{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for this code to work, the 'data/humans' folder needs to contain one sub-folder for each performed experiment. In each of these folders, the data for the different N values must be contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import ndtr\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import spearmanr, shapiro, ttest_rel, ttest_ind, sem\n",
    "import seaborn as sns\n",
    "from cmcrameri import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from math import sqrt, e\n",
    "import json\n",
    "from itertools import combinations\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAnalysisPipeline:\n",
    "    \n",
    "    def __init__(self, experiment_name, analysis_type=\"global\", log_scale_K0=False):\n",
    "        self.experiment_name = experiment_name\n",
    "        if analysis_type not in [\"global\", \"subject-wise\"]:\n",
    "            raise ValueError(\"analysis_type must be either 'global' or 'subject-wise'\")\n",
    "        self.analysis_type = analysis_type\n",
    "        self.log_scale_K0 = log_scale_K0\n",
    "        \n",
    "        # Define the path to the experiment directory:\n",
    "        experiment_path = Path(f'./data/humans/{self.experiment_name}')\n",
    "        if not experiment_path.exists():\n",
    "            raise ValueError(f\"Experiment directory {experiment_path} does not exist\")\n",
    "        \n",
    "        # Generate color palettes for global/subject-wise conditions\n",
    "        # - each folder corresponds to a different N value:\n",
    "        folders_N_values = [folder for folder in experiment_path.glob('*') if folder.is_dir()]\n",
    "        self.humans_palette_global = sns.color_palette(\"flare\", len(folders_N_values))\n",
    "        # - each file inside a single N folder is a different subject: \n",
    "        subjects = [file for file in folders_N_values[0].glob('*.csv') if file.is_file()]\n",
    "        print(\"Number of subjects for each N value: \", len(subjects))\n",
    "        self.humans_palette_subjects = sns.color_palette(\"husl\", len(subjects))        \n",
    "        #NOTE: this color palette assigns the same color to subjects having the same number, possible improvement is setting a different palette for each N value\n",
    "        \n",
    "        # Store list of N values in the current experiment (used to loop through all N values)\n",
    "        self.N_values = [int(folder.name[1:]) for folder in folders_N_values]\n",
    "                \n",
    "    \n",
    "    def read_raw_data(self):\n",
    "        print(\"|Reading raw data...\")\n",
    "        \n",
    "        # Creating an empty dataframe that will be populated with all the data:\n",
    "        humans_complete_raw_df = pd.DataFrame()\n",
    "\n",
    "        # Define the path to the experiment directory:\n",
    "        experiment_path = Path(f'./data/humans/{self.experiment_name}')\n",
    "\n",
    "        # Accessing all folders in the specified directory (each folder corresponds to a N value):\n",
    "        folders = experiment_path.glob('*')\n",
    "                \n",
    "        for folder in folders:\n",
    "            if folder.is_dir():\n",
    "                print(f\"||Entered folder: {folder}\")\n",
    "                \n",
    "                # Accessing all CSV files in the specified directory:\n",
    "                files = folder.glob('*.csv')\n",
    "                \n",
    "                for file_index, file in enumerate(files):\n",
    "                    if file.is_file():                        \n",
    "                        try:\n",
    "                            # Reading the CSV file:\n",
    "                            df = pd.read_csv(file)\n",
    "\n",
    "                            # Concatenating the dataframes (NOTE: assigning a subject number to each file)\n",
    "                            if self.experiment_name == \"2023-06_thesis-data\":\n",
    "                                df['subject_number'] = file_index + 1\n",
    "                            else:\n",
    "                                #NOTE (to implement): assign Prolific id instead of subject number? Maybe not, subject number assignment is fine\n",
    "                                raise ValueError(\"IMPLEMENT PROLIFIC ID ASSIGNMENT\")\n",
    "                                \n",
    "                            humans_complete_raw_df = pd.concat([humans_complete_raw_df, df], axis=0, ignore_index=True)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error reading file {file}: {e}\")\n",
    "                            return\n",
    "                    else:\n",
    "                        print(f\"File {file} does not exist.\")\n",
    "                        return\n",
    "        \n",
    "        self.humans_complete_raw_df = humans_complete_raw_df\n",
    "                \n",
    "        print(\"|Completed reading raw data.\")\n",
    "    \n",
    "    \n",
    "    def calculate_demographics(self):\n",
    "        print(\"|Calculating demographics.\")\n",
    "\n",
    "        #NOTE: in N-grid experiments, pooling data from all N values, no differentiation between N values in demographics\n",
    "        \n",
    "        # isolating survey trials to calculate average age:\n",
    "        humans_survey = self.humans_complete_raw_df[self.humans_complete_raw_df.trial_type == \"survey-html-form\"]\n",
    "        # initializations:\n",
    "        age = []    # list to store ages\n",
    "        female_count = 0\n",
    "        male_count = 0\n",
    "        transgender_count = 0\n",
    "        other = 0\n",
    "        not_specified = 0\n",
    "        # accessing ages and storing them:\n",
    "        for index, row in humans_survey.iterrows():            \n",
    "            try:\n",
    "                response_dict = json.loads(row.response)\n",
    "                # appending age to the list:\n",
    "                age.append(int(response_dict['age']))\n",
    "                # incrementing gender count:\n",
    "                match response_dict['gender']:\n",
    "                    case \"female\":\n",
    "                        female_count += 1\n",
    "                    case \"male\":\n",
    "                        male_count += 1\n",
    "                    case \"transgender\":\n",
    "                        transgender_count += 1\n",
    "                    case \"other\":\n",
    "                        other += 1\n",
    "                    case \"not-specified\":\n",
    "                        not_specified += 1\n",
    "                    case _:\n",
    "                        return \"Other\"\n",
    "                \n",
    "            except ValueError:\n",
    "                print(f\"Error reading dictionary for row {index}.\")                            \n",
    "        \n",
    "        # calculating average age and total female count:\n",
    "        try:\n",
    "            average_age = np.mean(age)\n",
    "            print(f\"Average age: {average_age}\")\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Error calculating average age: No valid age data found\")\n",
    "        \n",
    "        if self.experiment_name == \"2023-06_thesis-data\":\n",
    "            # in thesis data, same subjects performed the experiment at N=300 and N=1000, so we need to divide by 2\n",
    "            female_count =  female_count / 2\n",
    "            male_count = male_count / 2    \n",
    "        print(f\"Female count: {female_count}\")\n",
    "        print(f\"Male count: {male_count}\")\n",
    "        print(f\"Transgender count: {transgender_count}\")\n",
    "        print(f\"Other count: {other}\")\n",
    "        print(f\"Not specified count: {not_specified}\")\n",
    "        \n",
    "        print(\"|Completed calculating demographics.\")\n",
    "            \n",
    "    \n",
    "    # def calculate_devices_stats(self):\n",
    "    #TODO: analyze the different devices used by the subjects    \n",
    "    \n",
    "     \n",
    "    def clean_data(self):\n",
    "        print(\"|Cleaning data...\")\n",
    "        \n",
    "        try:\n",
    "            # cleaning raw data to access only relevant variables:\n",
    "            # - isolating experiment trials (\"canvas-keyboard-response\" ones) and dropping irrelevant variables:\n",
    "            cleaned_df = self.humans_complete_raw_df[self.humans_complete_raw_df.trial_type == \"canvas-keyboard-response\"]\n",
    "            # - dropping irrelevant variables:\n",
    "            cleaned_df = cleaned_df.drop([\"timeout\",\"failed_images\",\"failed_audio\",\"failed_video\",\"view_history\",\"trial_index\", \"time_elapsed\",\"internal_node_id\" ,\"success\",\"stimulus\",\"graphs_couple\"], axis=1).copy()\n",
    "            \n",
    "            # excluding trials where response times are <100ms:\n",
    "            #NOTE: rt<100ms trials are excluded from all analyses \n",
    "            cleaned_df_filtered = cleaned_df[cleaned_df['rt'].values >= 100]\n",
    "            excluded_trials = len(cleaned_df) - len(cleaned_df_filtered)  \n",
    "            print(f'Excluding {excluded_trials} trials where response time is less than 100ms. {len(cleaned_df_filtered)} trials remaining. Excluded {round((excluded_trials/len(cleaned_df))*100, 2)}% of trials.')\n",
    "\n",
    "            # differentiating trials:\n",
    "            # - final responses\n",
    "            self.cleaned_data_final_resp = cleaned_df_filtered[cleaned_df_filtered['response'].isin(['arrowright','arrowleft'])]\n",
    "            # - shuffle trials\n",
    "            self.cleaned_data_shuffles = cleaned_df_filtered[cleaned_df_filtered['response'].isin([' '])]\n",
    "            # - response times (keeping both shuffles and final responses)\n",
    "            self.cleaned_data_response_times = cleaned_df_filtered.copy()           \n",
    "\n",
    "            print(self.cleaned_data_response_times.tail())\n",
    "            \n",
    "            # adding control to check that the graph sizes in the experiment folder corresponds to the graph sizes in the cleaned data:\n",
    "            N_values_cleaned_data = self.cleaned_data_final_resp['graph_size'].unique()\n",
    "            for N_value_cleaned_data in N_values_cleaned_data:\n",
    "                if not N_value_cleaned_data in self.N_values:\n",
    "                    print(f\"N value {N_value_cleaned_data} in cleaned data is not present in the list of N values. Check that the data inside the folders corresponds to the N value indicated by the folder name.\")\n",
    "                    return \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning data: {e}\")\n",
    "        \n",
    "        print(\"|Completed cleaning data.\")\n",
    "        \n",
    "        \n",
    "    def calculate_fraction_correct(self):\n",
    "        print(\"|Calculating fraction correct...\")\n",
    "            \n",
    "        # initializations:\n",
    "        df_humans_fraction_correct_appended = []\n",
    "        for N_value in sorted(self.N_values):\n",
    "            # isolating data of current N value:\n",
    "            currentN_data = self.cleaned_data_final_resp[self.cleaned_data_final_resp.graph_size == N_value]\n",
    "            # isolating the single values of K:\n",
    "            K_range = currentN_data['clique_size'].unique()\n",
    "            for K_value in K_range:\n",
    "                if self.analysis_type == \"global\":\n",
    "                    # isolating data of current clique size:\n",
    "                    currentK_data = currentN_data[currentN_data.clique_size == K_value]\n",
    "                    # calculating accuracy for current clique size (\"correct\", when present, is either True or False)\n",
    "                    if self.experiment_name == \"2023-06_thesis-data\":\n",
    "                        fraction_correct_currentK = sum(currentK_data.accuracy) / sum(~ currentK_data.accuracy.isna())\n",
    "                    else:\n",
    "                        fraction_correct_currentK = sum(currentK_data.correct) / sum(~ currentK_data.correct.isna())\n",
    "                    # appending data to the list:\n",
    "                    df_humans_fraction_correct_appended.append(pd.DataFrame({'N':[N_value], 'K':[K_value], 'fc':[fraction_correct_currentK]}))\n",
    "                elif self.analysis_type == \"subject-wise\":\n",
    "                    for subject_number in currentN_data['subject_number'].unique():\n",
    "                        # isolating data of current clique size and subject number:\n",
    "                        currentK_data = currentN_data[(currentN_data.clique_size == K_value) & (currentN_data.subject_number == subject_number)]\n",
    "                        # calculating accuracy (\"correct\", when present, is either True or False)\n",
    "                        if self.experiment_name == \"2023-06_thesis-data\":\n",
    "                            fraction_correct_currentK = sum(currentK_data.accuracy) / sum(~ currentK_data.accuracy.isna())\n",
    "                        else:\n",
    "                            fraction_correct_currentK = sum(currentK_data.correct) / sum(~ currentK_data.correct.isna())\n",
    "                        # appending data to the list:\n",
    "                        df_humans_fraction_correct_appended.append(pd.DataFrame({'subject_number':[subject_number],'N':[N_value], 'K':[K_value], 'fc':[fraction_correct_currentK]}))\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid analysis type\")\n",
    "\n",
    "        # creating single df for current N value:   \n",
    "        df_humans_fraction_correct = pd.concat(df_humans_fraction_correct_appended)\n",
    "        # creating new variable and adding it to the dataframe:\n",
    "        df_humans_fraction_correct['K/sqrt(N)'] = df_humans_fraction_correct['K']/np.sqrt(df_humans_fraction_correct['N'])\n",
    "        # creating new variable and adding it to the dataframe:\n",
    "        df_humans_fraction_correct['K/N'] = df_humans_fraction_correct['K']/df_humans_fraction_correct['N']\n",
    "        # saving dataframe:\n",
    "        self.df_humans_fraction_correct = df_humans_fraction_correct\n",
    "        # visualizing dataframe:\n",
    "        display(df_humans_fraction_correct)  \n",
    "        print(\"|Completed calculating fraction correct.\")      \n",
    "    \n",
    "    def generate_boxplot(self):\n",
    "    # Description:\n",
    "    # Boxplot to compare the fraction of correct responses at different N values (emerging trend: larger N -> larger fraction correct)  \n",
    "\n",
    "        print(\"|Generating boxplot...\") \n",
    "        \n",
    "        # creating unique figure (width variable baed on N values):\n",
    "        fig, ax = plt.subplots(figsize=(3 * len(self.df_humans_fraction_correct['N'].unique()), 4))\n",
    "                \n",
    "        ax.set_xlim([80, 1020])\n",
    "        ax.set_ylim([0.5, 1])        \n",
    "        \n",
    "        # creating dataframe containing only data to plot\n",
    "        average_fc_df = self.df_humans_fraction_correct.groupby(['subject_number', 'N'])['fc'].mean().reset_index()\n",
    "        \n",
    "        # swarmplot with single subjects:\n",
    "        ax = sns.stripplot(data=average_fc_df, x='N', y='fc', hue='subject_number', palette=self.humans_palette_subjects, s=7, alpha=0.7, legend=False)\n",
    "        # adding corresponding mean value as a point over each swarmplot:\n",
    "        ax.scatter([str(i) for i in sorted(self.N_values)], average_fc_df.groupby('N')['fc'].mean().values, color=self.humans_palette_global, s=120, marker='o')\n",
    "\n",
    "        # Generate legend for average points:\n",
    "        handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=self.humans_palette_global[i], markersize=10) for i in range(len(self.N_values))]\n",
    "        ax.legend(handles, [f'N = {i}' for i in sorted(self.N_values)], title='Average fraction correct', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "                \n",
    "        ax.set_xlabel('Number of nodes', size=12)\n",
    "        ax.set_ylabel('Fraction correct', size=12)\n",
    "        ax.set_title('Fraction correct as a function of N', size=14)\n",
    "        \n",
    "        # saving figure in corresponding \"plots/humans\" folder\n",
    "        plt.savefig(f'./plots/humans/{self.experiment_name}/humans-boxplot_{self.experiment_name}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "        plt.savefig(f'./plots/humans/{self.experiment_name}/humans-boxplot_{self.experiment_name}.png', dpi=300, bbox_inches=\"tight\")\n",
    "       \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"|Completed generating boxplot.\")\n",
    "        \n",
    "        \n",
    "    def calculate_boxplot_stats(self):\n",
    "        # Description:\n",
    "        # - comparing mean fraction correct at different N values to check if they differ significantly (emerging trend: larger N -> larger fraction correct).\n",
    "        # NOTE:\n",
    "        # 1. this is a global analysis (no subject information)\n",
    "        # 2. differentiating test based on the number of N values (ANOVA for more than 2 N values, t-test for 2 N values)\n",
    "        # 3. not creating dataframe, only printing values\n",
    "        # 4. setting alternative='less' to check for increase in fraction correct for larger N values\n",
    "        \n",
    "        # creating dataframe containing only data to analyze\n",
    "        average_fc_df = self.df_humans_fraction_correct.groupby(['subject_number', 'N'])['fc'].mean().reset_index()        \n",
    "        \n",
    "        # calculating mean and standard error of the mean for all N values:\n",
    "        for N_value in sorted(self.N_values):\n",
    "            print(f\"Mean fraction correct for N = {N_value}: {average_fc_df[average_fc_df['N'] == N_value]['fc'].mean()} +- {sem(average_fc_df[average_fc_df['N'] == N_value]['fc'])}\")\n",
    "        \n",
    "        # differentiating analysis based on number of N values:\n",
    "        if len(self.N_values) == 2:\n",
    "            print(\"|Calculating boxplot stats (2 N values -> t-test)...\")\n",
    "            # checking t-test assumptions:\n",
    "            # - normality\n",
    "            print(\"Shapiro-Wilk test for normality:\")\n",
    "            print(f\"- for {sorted(self.N_values)[0]}: {shapiro(average_fc_df[average_fc_df['N'] == sorted(self.N_values)[0]]['fc'])}\")\n",
    "            print(f\"- for {sorted(self.N_values)[1]}: {shapiro(average_fc_df[average_fc_df['N'] == sorted(self.N_values)[1]]['fc'])}\")                        \n",
    "            # performing t-test:            \n",
    "            if self.experiment_name == \"2023-06_thesis-data\":\n",
    "                print(\"thesis data\")\n",
    "                # in the thesis data, the two samples are dependent (same subjects)\n",
    "                t_test_stat = ttest_rel(average_fc_df[average_fc_df['N'] == sorted(self.N_values)[0]]['fc'], average_fc_df[average_fc_df['N'] == sorted(self.N_values)[1]]['fc'], alternative='less')\n",
    "            else:\n",
    "                # in general, the two samples are independent (different subjects)\n",
    "                t_test_stat = ttest_ind(average_fc_df[average_fc_df['N'] == sorted(self.N_values)[0]]['fc'], average_fc_df[average_fc_df['N'] == sorted(self.N_values)[1]]['fc'], alternative='less')\n",
    "            # printing t-test results \n",
    "            print(f\"t-statistic: {t_test_stat.statistic}, p-value: {t_test_stat.pvalue}\")            \n",
    "                 \n",
    "        elif len(self.N_values) > 2:\n",
    "            print(\"|Calculating boxplot stats (more than 2 N values -> ANOVA)...\")\n",
    "            #TODO: implement ANOVA test for N-grid case\n",
    "            # checking ANOVA assumptions:\n",
    "            \n",
    "            # performing ANOVA test:\n",
    "\n",
    "            # adding stats to pipeline / printing results\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Only one N value, cannot perform statistical test\")\n",
    "                \n",
    "            \n",
    "    def calculate_fitted_params(self):\n",
    "        print(\"|Calculating fitted parameters...\")\n",
    "        \n",
    "        def sigmoid(k, k0, delta):\n",
    "            return (1+ndtr((k-k0)/delta))/2 \n",
    "        \n",
    "        # empty dataframe where fitted parameters will be stored:\n",
    "        df_humans_fitted_params_appended = []\n",
    "        \n",
    "        # looping through all N values:\n",
    "        for N_value in sorted(self.N_values):\n",
    "            # selecting trials for current N value:\n",
    "            current_data = self.df_humans_fraction_correct[self.df_humans_fraction_correct['N']==N_value]\n",
    "            if self.analysis_type == \"global\":\n",
    "                # calculating fitted parameters:\n",
    "                fitted_params = curve_fit(sigmoid, current_data['K'], current_data['fc'], p0=(70, 20))[0]\n",
    "                # adding fitted parameters to the dataframe (K0 and Delta):\n",
    "                df_humans_fitted_params_appended.append(pd.DataFrame({'N': [N_value], 'K0':[fitted_params[0]], 'Delta':[fitted_params[1]]}))\n",
    "            elif self.analysis_type == \"subject-wise\":\n",
    "                # looping through all subjects for current N value:\n",
    "                for subject in current_data['subject_number'].unique():\n",
    "                    # accessing data for current subject:\n",
    "                    current_subject_data = current_data[current_data['subject_number'] == subject]\n",
    "                    # calculating fitted parameters:\n",
    "                    fitted_params = curve_fit(sigmoid, current_subject_data['K'], current_subject_data['fc'], p0=(70, 20))[0]\n",
    "                    # adding fitted parameters to the dataframe:\n",
    "                    df_humans_fitted_params_appended.append(pd.DataFrame({'subject_number':[subject], 'N': [N_value], 'K0':[fitted_params[0]], 'Delta':[fitted_params[1]]}))\n",
    "\n",
    "        # concatenating dataframe of fitted parameters:\n",
    "        df_humans_fitted_params = pd.concat(df_humans_fitted_params_appended)\n",
    "        # saving dataframe:\n",
    "        self.df_humans_fitted_params = df_humans_fitted_params\n",
    "        # visualizing dataframe:\n",
    "        display(df_humans_fitted_params)\n",
    "        print(\"|Completed calculating fitted parameters.\")\n",
    "    \n",
    "    \n",
    "    def generate_psychometrics(self):\n",
    "        print(\"|Generating psychometric curves...\")\n",
    "        \n",
    "        # defining x values:\n",
    "        x_vals = np.linspace(0, 0.4*max(self.df_humans_fraction_correct['N'].unique()), 1000)       \n",
    "        \n",
    "        # DRAWING THE PSYCHOMETRIC CURVES\n",
    "        if self.analysis_type == \"global\":\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "            # - two subplots showing the global psychometric curves. The one on the left shows K on x-axis, the one on the right shows K/N on x-axis.\n",
    "            # - K on x-axis:\n",
    "            sns.scatterplot(data=self.df_humans_fraction_correct, x='K', y='fc', ax=ax[0], s=10, hue='N', palette=self.humans_palette_global)\n",
    "            # - K/N on x-axis:\n",
    "            sns.scatterplot(data=self.df_humans_fraction_correct, x='K/N', y='fc', ax=ax[1], s=10, hue='N', palette=self.humans_palette_global)\n",
    "            for i, N_value in enumerate(sorted(self.N_values)):\n",
    "                # defining y values for the psychometric curve: \n",
    "                k0 = self.df_humans_fitted_params[(self.df_humans_fitted_params['N'] == N_value)]['K0'].values[0]\n",
    "                delta = self.df_humans_fitted_params[(self.df_humans_fitted_params['N'] == N_value)]['Delta'].values[0]\n",
    "                y_vals = (1 + ndtr((x_vals - k0) / delta)) / 2\n",
    "                # creating dataframe to plot the line using seaborn:\n",
    "                df_line = pd.DataFrame({'N': N_value, 'K': x_vals, 'fc': y_vals})\n",
    "                df_line['K/N'] = df_line['K']/df_line['N']\n",
    "                # plotting the psychometric curve:\n",
    "                sns.lineplot(data=df_line, x='K', y='fc', ax=ax[0], color=self.humans_palette_global[i])  \n",
    "                sns.lineplot(data=df_line, x='K/N', y='fc', ax=ax[1], color=self.humans_palette_global[i])                          \n",
    "            \n",
    "            ax[0].set_ylabel(\"Fraction correct\")\n",
    "            ax[0].set_xlabel(\"Clique size\")\n",
    "            ax[0].tick_params(axis='x')\n",
    "            ax[0].tick_params(axis='y')\n",
    "            ax[0].set_title(\"Psychometric curves (K on x-axis)\")\n",
    "            ax[1].set_ylabel(\"Fraction correct\")\n",
    "            ax[1].set_xlabel(\"Clique size / N\")\n",
    "            ax[1].set_xlim(ax[1].get_xlim()[0], 0.6)\n",
    "            ax[1].tick_params(axis='x')\n",
    "            ax[1].tick_params(axis='y')\n",
    "            ax[1].set_title(\"Psychometric curves (K/N on x-axis)\") \n",
    "            \n",
    "            # adjusting layout and saving figure:\n",
    "            plt.tight_layout()\n",
    "            # saving figure in corresponding \"plots/humans\" folder       \n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-psychometric-curves_{self.experiment_name}_global.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-psychometric-curves_{self.experiment_name}_global.png', dpi=300, bbox_inches=\"tight\")  \n",
    "                \n",
    "        elif self.analysis_type == \"subject-wise\":     \n",
    "            # - create subplots based on the number of N values and subjects:\n",
    "            n_values = len(self.df_humans_fraction_correct['N'].unique())\n",
    "            subjects = len(self.df_humans_fraction_correct['subject_number'].unique())    \n",
    "            fig, ax = plt.subplots(n_values, subjects, figsize=(5 * subjects, 4 * n_values), constrained_layout=True)\n",
    "\n",
    "            # - loop through the N values:\n",
    "            for i, N_value in enumerate(sorted(self.N_values)):\n",
    "                # isolating data for current N value:\n",
    "                current_data = self.df_humans_fraction_correct[self.df_humans_fraction_correct['N'] == N_value]\n",
    "        \n",
    "                # defining y values and plotting the scatterplot and the psychometric curve:\n",
    "                for j, subject_number in enumerate(current_data['subject_number'].unique()):\n",
    "                    # drawing scatterplot based on fraction correct dataframe:\n",
    "                    subject_data = current_data[current_data['subject_number'] == subject_number]\n",
    "                    sns.scatterplot(data=subject_data, x='K', y='fc', color=self.humans_palette_subjects[j], ax=ax[i, j], s=10)\n",
    "                    # defining y values and plotting the psychometric curve:\n",
    "                    k0 = self.df_humans_fitted_params[(self.df_humans_fitted_params['N'] == N_value) & (self.df_humans_fitted_params['subject_number'] == subject_number)]['K0'].values[0]\n",
    "                    delta = self.df_humans_fitted_params[(self.df_humans_fitted_params['N'] == N_value) & (self.df_humans_fitted_params['subject_number'] == subject_number)]['Delta'].values[0]\n",
    "                    y_vals = (1 + ndtr((x_vals - k0) / delta)) / 2\n",
    "                    ax[i, j].plot(x_vals, y_vals, color=self.humans_palette_subjects[j], label=f'Subject {subject_number}')\n",
    "                    ax[i, j].set_ylabel(\"Fraction correct\")\n",
    "                    ax[i, j].set_xlabel(\"Clique size\")    \n",
    "                    ax[i, j].tick_params(axis='x')\n",
    "                    ax[i, j].tick_params(axis='y')\n",
    "                    ax[i, j].set_title(f\"N = {int(N_value)}, Subject {subject_number}\")\n",
    "\n",
    "            # adjusting layout and saving figure:\n",
    "            plt.tight_layout()\n",
    "            # saving figure in corresponding \"plots/humans\" folder\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-psychometric-curves_{self.experiment_name}_subjects.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-psychometric-curves_{self.experiment_name}_subjects.png', dpi=300, bbox_inches=\"tight\")\n",
    "                                         \n",
    "        else:\n",
    "            raise ValueError(\"Invalid analysis type\")\n",
    "              \n",
    "         \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    \n",
    "        print(\"|Completed generating psychometric curves.\")\n",
    "        \n",
    "        \n",
    "    def calculate_shuffles_df(self):\n",
    "        print(\"|Calculating shuffles dataframe...\")\n",
    "        \n",
    "        # initializations:\n",
    "        df_humans_mean_shuffles_appended = []\n",
    "        \n",
    "        # retrieving the number of trials for a given clique size value in the whole experiment (used to normalize the number of shuffles):\n",
    "        N_trials_per_K_value = self.cleaned_data_final_resp.groupby(['graph_size', 'clique_size', 'subject_number']).size().reset_index(name='count')\n",
    "        print(\"Number of trials per clique size in the whole exp:\", N_trials_per_K_value['count'].iloc[0])\n",
    "        \n",
    "        # looping through all N values, clique size values and subjects\n",
    "        for N_value in sorted(self.N_values):\n",
    "            currentN_data = self.cleaned_data_final_resp[self.cleaned_data_final_resp.graph_size == N_value]\n",
    "            # looping through all K values for current N value:\n",
    "            for K_value in currentN_data['clique_size'].unique():\n",
    "                currentK_data = currentN_data[currentN_data.clique_size == K_value]\n",
    "                # looping through all subjects for current N and K values:\n",
    "                for subject_number in currentK_data['subject_number'].unique():\n",
    "                    # isolating data of current N value, K value and subject number (NOTE: using self.cleaned_data_shuffles here)\n",
    "                    currentK_subject_shuffles = self.cleaned_data_shuffles[(self.cleaned_data_shuffles.graph_size == N_value) & (self.cleaned_data_shuffles.clique_size == K_value) & (self.cleaned_data_shuffles.subject_number == subject_number)]\n",
    "                    # counting the number of shuffles for current subject for current N and K values:\n",
    "                    mean_shuffles_subject = len(currentK_subject_shuffles) / N_trials_per_K_value['count'].iloc[0]  # normalizing by the number of trials for a given clique size value in the whole experiment\n",
    "                    # appending data to the list:\n",
    "                    df_humans_mean_shuffles_appended.append(pd.DataFrame({'subject_number':[subject_number],'N':[N_value], 'K': [K_value], 'mean_shuffles':[mean_shuffles_subject]}))\n",
    "\n",
    "        # creating single df:   \n",
    "        df_humans_shuffles = pd.concat(df_humans_mean_shuffles_appended)\n",
    "        # creating new variable and adding it to the dataframe:\n",
    "        df_humans_shuffles['K/N'] = df_humans_shuffles['K']/df_humans_shuffles['N']\n",
    "        # saving dataframe:\n",
    "        self.df_humans_shuffles = df_humans_shuffles\n",
    "        # visualizing dataframe:\n",
    "        display(self.df_humans_shuffles)  \n",
    "                \n",
    "        print(\"|Completed calculating shuffles dataframe.\")\n",
    "        \n",
    "    \n",
    "    def generate_shuffles_graphs(self):\n",
    "        \n",
    "        print(\"|Generating shuffles graphs...\")\n",
    "\n",
    "        if self.analysis_type == \"global\":                    \n",
    "            fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "            # - K on x-axis:\n",
    "            sns.lineplot(data = self.df_humans_shuffles, x = 'K', y = 'mean_shuffles', hue='N', palette=self.humans_palette_global, errorbar='se', linestyle='-', marker='o', ax=ax[0])\n",
    "            # - K/N on x-axis:\n",
    "            sns.lineplot(data = self.df_humans_shuffles, x = 'K/N', y = 'mean_shuffles', hue='N', palette=self.humans_palette_global, errorbar='se', linestyle='-', marker='o', ax=ax[1])\n",
    "\n",
    "            # plotting K0s as vertical red dashed lines:\n",
    "            for i, N_value in enumerate(sorted(self.N_values)):\n",
    "                K0 = self.df_humans_fitted_params[self.df_humans_fitted_params['N'] == N_value]['K0'].values[0]\n",
    "                ax[0].axvline(K0, color=self.humans_palette_global[i], linestyle='--', linewidth=1.5)\n",
    "                # adding label to K0 line at the top of the figure, increasing size of text:\n",
    "                ax[0].text(K0+0.5, 3, 'K₀', color=self.humans_palette_global[i], ha='left', va='top', fontsize=15)\n",
    "                ax[1].axvline(K0/N_value, color=self.humans_palette_global[i], linestyle='--', linewidth=1.5)\n",
    "                # adding label to K0 line at the top of the figure, increasing size of text:\n",
    "                ax[1].text(K0/N_value+0.005, 3, 'K₀', color=self.humans_palette_global[i], ha='left', va='top', fontsize=15)\n",
    "            \n",
    "                # setting labels and title:\n",
    "                ax[0].set_xlim(ax[0].get_xlim()[0], 320)\n",
    "                ax[0].set_ylim(-0.5, 4)\n",
    "                ax[0].set_ylabel(\"Number of shuffles\")\n",
    "                ax[0].set_xlabel(\"Clique size\")\n",
    "                ax[0].tick_params(axis='x')\n",
    "                ax[0].tick_params(axis='y')\n",
    "                ax[0].set_title(\"Number of shuffles as a function of K\")\n",
    "                ax[1].set_xlim(ax[1].get_xlim()[0], 0.3)\n",
    "                ax[1].set_ylim(-0.5, 4)\n",
    "                ax[1].set_ylabel(\"Number of shuffles\")\n",
    "                ax[1].set_xlabel(\"Clique size / N\")\n",
    "                ax[1].tick_params(axis='x')\n",
    "                ax[1].tick_params(axis='y')\n",
    "                ax[1].set_title(\"Number of shuffles as a function of K / N\")\n",
    "                \n",
    "                # adjusting layout and saving figure:\n",
    "                plt.tight_layout()\n",
    "                plt.subplots_adjust(wspace=0.5)\n",
    "                \n",
    "                # saving figure in corresponding \"plots/humans\" folder\n",
    "                plt.savefig(f'./plots/humans/{self.experiment_name}/humans-shuffles-graphs_{self.experiment_name}_global.svg', dpi=300, bbox_inches=\"tight\")\n",
    "                plt.savefig(f'./plots/humans/{self.experiment_name}/humans-shuffles-graphs_{self.experiment_name}_global.png', dpi=300, bbox_inches=\"tight\")\n",
    "        \n",
    "        elif self.analysis_type == \"subject-wise\":            \n",
    "            \n",
    "            # creating one subplot for each N value:\n",
    "            fig, axes = plt.subplots(nrows=len(self.df_humans_fitted_params['N'].unique()), ncols=1, figsize=(7, 8))\n",
    "            \n",
    "            # - loop through the N values:        \n",
    "            for i, N_value in enumerate(sorted(self.N_values)):\n",
    "                # isolating data for current N value:\n",
    "                currentN_shuffles = self.df_humans_shuffles[self.df_humans_shuffles['N'] == N_value]\n",
    "                ax = axes[i]\n",
    "                sns.lineplot(data=currentN_shuffles, x='K', y='mean_shuffles', hue='subject_number', palette=self.humans_palette_subjects, legend=False, linewidth=1, marker='o', linestyle='--', ax=ax)\n",
    "                # calculating the mean number of shuffles for current N value across all subjects:\n",
    "                mean_shuffles = currentN_shuffles.groupby('K')['mean_shuffles'].mean()\n",
    "                # create dataframe of mean number of shuffles to use seaborn, using .index and .values:\n",
    "                mean_df = pd.DataFrame({'clique_size': mean_shuffles.index, 'mean_shuffles': mean_shuffles.values})\n",
    "                # Plotting the mean number of shuffles as a red line with dots as markers\n",
    "                sns.lineplot(data = mean_df, x = 'clique_size', y = 'mean_shuffles', color=self.humans_palette_global[i], markersize=10, linewidth=2, marker='o', ax=ax, label='Average')\n",
    "                # calculating mean K0 value for current N value:\n",
    "                K0_value = self.df_humans_fitted_params[self.df_humans_fitted_params['N'] == N_value]['K0'].mean()\n",
    "                \n",
    "                print(f\"Mean K0 value for N = {N_value}: {K0_value}\")\n",
    "                \n",
    "                # plotting vertical red dashed line for K0:\n",
    "                ax.axvline(K0_value, color=self.humans_palette_global[i], linestyle='--', linewidth=2)\n",
    "                # adding label to K0 line at the top of the figure, increasing size of text:\n",
    "                ax.text(K0_value, 3, 'K₀', color=self.humans_palette_global[i], ha='left', va='top', fontsize=15)\n",
    "                \n",
    "                # setting labels and title:\n",
    "                ax.set_xlabel('Clique size')\n",
    "                ax.set_ylabel('Number of shuffles')\n",
    "                ax.set_title(f'Number of shuffles as a function of clique size (N = {N_value})')\n",
    "                ax.tick_params(axis='x')\n",
    "                ax.tick_params(axis='y')\n",
    "        \n",
    "            # adjusting layout and saving figure:\n",
    "            plt.tight_layout()        \n",
    "            plt.subplots_adjust(hspace=0.5)    \n",
    "        \n",
    "            # saving figure in corresponding \"plots/humans\" folder\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-shuffles-graphs_{self.experiment_name}_subjects.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-shuffles-graphs_{self.experiment_name}_subjects.png', dpi=300, bbox_inches=\"tight\")\n",
    "                              \n",
    "        else:\n",
    "            raise ValueError(\"Invalid analysis type\")    \n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    \n",
    "    def calculate_shuffles_stats(self):\n",
    "        print(\"|Calculating shuffles stats...\")\n",
    "        \n",
    "        # Description:\n",
    "        # - calculating Spearman correlation to check if the number of shuffles is correlated with the clique size value (K).\n",
    "        # NOTE: in this case, no differentiation between global and subject-wise analysis\n",
    "        \n",
    "        # initialization:\n",
    "        df_humans_shuffles_stats_appended = []\n",
    "        # - isolating data for each N value:\n",
    "        for i, N_value in enumerate(sorted(self.N_values)):\n",
    "            print(f\"Calculating shuffles stats for N = {N_value}\")\n",
    "            currentN_shuffles = self.df_humans_shuffles[self.df_humans_shuffles['N'] == N_value]\n",
    "            shuffles_stat = spearmanr(currentN_shuffles['mean_shuffles'], currentN_shuffles['K'], alternative='less')\n",
    "            print(f\"Spearman correlation coefficient for N = {N_value}: {shuffles_stat.correlation}\")\n",
    "            print(f\"P-value for N = {N_value}: {shuffles_stat.pvalue}\")\n",
    "            df_humans_shuffles_stats_appended.append(pd.DataFrame({'N': [N_value], 'correlation':[shuffles_stat.correlation], 'p-value':[shuffles_stat.pvalue]}))\n",
    "        # creating single df:\n",
    "        df_humans_shuffles_stats = pd.concat(df_humans_shuffles_stats_appended)\n",
    "        self.df_humans_shuffles_stats = df_humans_shuffles_stats\n",
    "        display(df_humans_shuffles_stats)\n",
    "        \n",
    "        print(\"|Completed calculating shuffles stats.\")\n",
    "    \n",
    "    \n",
    "    def calculate_response_times_df(self):\n",
    "        print(\"|Calculating response times dataframe...\")\n",
    "        \n",
    "        # initializations:\n",
    "        df_humans_mean_response_times_appended = []\n",
    "        \n",
    "        # looping through all N values, clique size values and subjects\n",
    "        for N_value in sorted(self.N_values):\n",
    "            currentN_data = self.cleaned_data_response_times[self.cleaned_data_response_times.graph_size == N_value]\n",
    "            # looping through all K values for current N value:\n",
    "            for K_value in currentN_data['clique_size'].unique():\n",
    "                currentK_data = currentN_data[currentN_data.clique_size == K_value]\n",
    "                # looping through all subjects for current N and K values:\n",
    "                for subject_number in currentK_data['subject_number'].unique():\n",
    "                    # isolating data of current N value, K value and subject number\n",
    "                    currentK_subject_response_times = self.cleaned_data_response_times[(self.cleaned_data_response_times.graph_size == N_value) & (self.cleaned_data_response_times.clique_size == K_value) & (self.cleaned_data_response_times.subject_number == subject_number)]\n",
    "                    # calculating mean response times for current subject for current N and K values (converting to seconds):\n",
    "                    mean_response_times_subject = currentK_subject_response_times['rt'].mean() / 1000\n",
    "                    # appending data to the list:\n",
    "                    df_humans_mean_response_times_appended.append(pd.DataFrame({'subject_number':[subject_number],'N':[N_value], 'K': [K_value], 'mean_resp_time':[mean_response_times_subject]}))\n",
    "\n",
    "        # creating single df:   \n",
    "        df_humans_response_times = pd.concat(df_humans_mean_response_times_appended)\n",
    "        # creating new variable and adding it to the dataframe:\n",
    "        df_humans_response_times['K/N'] = df_humans_response_times['K']/df_humans_response_times['N']\n",
    "        # saving dataframe:\n",
    "        self.df_humans_response_times = df_humans_response_times\n",
    "        # visualizing dataframe:\n",
    "        display(self.df_humans_response_times)  \n",
    "                \n",
    "        print(\"|Completed calculating response times dataframe.\")\n",
    "        \n",
    "    \n",
    "    def generate_response_times_graphs(self):\n",
    "        \n",
    "        print(\"|Generating response times graphs...\")\n",
    "\n",
    "        if self.analysis_type == \"global\":                    \n",
    "            fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "            # - K on x-axis:\n",
    "            sns.lineplot(data = self.df_humans_response_times, x = 'K', y = 'mean_resp_time', hue='N', palette=self.humans_palette_global, errorbar='se', linestyle='-', marker='o', ax=ax[0])\n",
    "            # - K/N on x-axis:\n",
    "            sns.lineplot(data = self.df_humans_response_times, x = 'K/N', y = 'mean_resp_time', hue='N', palette=self.humans_palette_global, errorbar='se', linestyle='-', marker='o', ax=ax[1])\n",
    "\n",
    "            # plotting K0s as vertical red dashed lines:\n",
    "            for i, N_value in enumerate(sorted(self.N_values)):\n",
    "                K0 = self.df_humans_fitted_params[self.df_humans_fitted_params['N'] == N_value]['K0'].values[0]\n",
    "                ax[0].axvline(K0, color=self.humans_palette_global[i], linestyle='--', linewidth=1.5)\n",
    "                # adding label to K0 line at the top of the figure, increasing size of text:\n",
    "                ax[0].text(K0+5, 3.8, 'K₀', color=self.humans_palette_global[i], ha='left', va='top', fontsize=15)\n",
    "                ax[1].axvline(K0/N_value, color=self.humans_palette_global[i], linestyle='--', linewidth=1.5)\n",
    "                # adding label to K0 line at the top of the figure, increasing size of text:\n",
    "                ax[1].text(K0/N_value+0.005, 3.8, 'K₀', color=self.humans_palette_global[i], ha='left', va='top', fontsize=15)\n",
    "            \n",
    "                # setting labels and title:\n",
    "                ax[0].set_xlim(ax[0].get_xlim()[0], 320)\n",
    "                ax[0].set_ylabel(\"Response time (s, log-scaled)\")\n",
    "                ax[0].set_xlabel(\"Clique size\")\n",
    "                ax[0].tick_params(axis='x')\n",
    "                ax[0].tick_params(axis='y')\n",
    "                ax[0].set_title(\"Response time as a function of K\")\n",
    "                ax[1].set_xlim(ax[1].get_xlim()[0], 0.3)\n",
    "                ax[1].set_ylabel(\"Response time (s, log-scaled)\")\n",
    "                ax[1].set_xlabel(\"Clique size / N\")\n",
    "                ax[1].tick_params(axis='x')\n",
    "                ax[1].tick_params(axis='y')\n",
    "                ax[1].set_title(\"Response time as a function of K / N\")\n",
    "                \n",
    "                # Log-scaling the y-axis  \n",
    "                ax[0].set_yscale('log', base=2)\n",
    "                # Using ScalarFormatter to format the y-axis with actual numbers instead of powers of 2\n",
    "                ax[0].yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "                ax[0].autoscale()      \n",
    "                # Log-scaling the y-axis  \n",
    "                ax[1].set_yscale('log', base=2)\n",
    "                # Using ScalarFormatter to format the y-axis with actual numbers instead of powers of 2\n",
    "                ax[1].yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "                ax[1].autoscale()                                \n",
    "                \n",
    "                # adjusting layout and saving figure:\n",
    "                # plt.tight_layout()\n",
    "                plt.subplots_adjust(wspace=0.6)\n",
    "                \n",
    "                # saving figure in corresponding \"plots/humans\" folder\n",
    "                plt.savefig(f'./plots/humans/{self.experiment_name}/humans-response-times-graphs_{self.experiment_name}_global.svg', dpi=300, bbox_inches=\"tight\")\n",
    "                plt.savefig(f'./plots/humans/{self.experiment_name}/humans-response-times-graphs_{self.experiment_name}_global.png', dpi=300, bbox_inches=\"tight\")\n",
    "        \n",
    "        elif self.analysis_type == \"subject-wise\":            \n",
    "            \n",
    "            # creating one subplot for each N value:\n",
    "            fig, axes = plt.subplots(nrows=len(self.N_values), ncols=1, figsize=(10, 8))\n",
    "            \n",
    "            # - loop through the N values:        \n",
    "            for i, N_value in enumerate(sorted(self.N_values)):\n",
    "                # isolating data for current N value:\n",
    "                currentN_resp_times = self.df_humans_response_times[self.df_humans_response_times['N'] == N_value]\n",
    "                ax = axes[i]\n",
    "                sns.lineplot(data=currentN_resp_times, x='K', y='mean_resp_time', hue='subject_number', palette=self.humans_palette_subjects, legend=False, linewidth=1, marker='o', linestyle='--', ax=ax)\n",
    "                # calculating the mean response time for current N value across all subjects:\n",
    "                mean_resp_time = currentN_resp_times.groupby('K')['mean_resp_time'].mean()\n",
    "                # create dataframe of mean response time to use seaborn, using .index and .values:\n",
    "                mean_df = pd.DataFrame({'clique_size': mean_resp_time.index, 'mean_resp_time': mean_resp_time.values})\n",
    "                # Plotting the mean response time as a red line with dots as markers\n",
    "                sns.lineplot(data = mean_df, x = 'clique_size', y = 'mean_resp_time', color=self.humans_palette_global[i], markersize=10, linewidth=2, marker='o', ax=ax, label='Average')\n",
    "                # calculating mean K0 value for current N value:\n",
    "                K0_value = self.df_humans_fitted_params[self.df_humans_fitted_params['N'] == N_value]['K0'].mean()\n",
    "                \n",
    "                # plotting vertical red dashed line for K0:\n",
    "                ax.axvline(K0_value, color=self.humans_palette_global[i], linestyle='--', linewidth=2)\n",
    "                # adding label to K0 line at the top of the figure, increasing size of text:\n",
    "                ax.text(K0_value+1, 8, 'K₀', color=self.humans_palette_global[i], ha='left', va='top', fontsize=15)\n",
    "                \n",
    "                # setting labels and title:\n",
    "                ax.set_xlabel('Clique size')\n",
    "                ax.set_ylabel('Response time (s, log-scaled)')\n",
    "                ax.set_title(f'Response time as a function of clique size (N = {N_value})')\n",
    "                ax.tick_params(axis='x')\n",
    "                ax.tick_params(axis='y')\n",
    "        \n",
    "                # Log-scaling the y-axis  \n",
    "                ax.set_yscale('log', base=2)\n",
    "                ax.set_ylim(0, *ax.get_ylim()[1:])\n",
    "                # Using ScalarFormatter to format the y-axis with actual numbers instead of powers of 2\n",
    "                ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "                ax.autoscale()      \n",
    "                        \n",
    "            # adjusting layout and saving figure:\n",
    "            plt.tight_layout()        \n",
    "            plt.subplots_adjust(hspace=0.6)    \n",
    "        \n",
    "            # saving figure in corresponding \"plots/humans\" folder\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-response-times-graphs_{self.experiment_name}_subjects.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-response-times-graphs_{self.experiment_name}_subjects.png', dpi=300, bbox_inches=\"tight\")\n",
    "                              \n",
    "        else:\n",
    "            raise ValueError(\"Invalid analysis type\")    \n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    \n",
    "        print(\"|Completed generating response times graphs.\")\n",
    "    \n",
    "    \n",
    "    def calculate_response_times_stats(self):\n",
    "        print(\"|Calculating response times stats...\")\n",
    "        \n",
    "        # Description:\n",
    "        # - t-test to check if response times are significantly larger for K value closest to K0 than for the smallest K value.\n",
    "        # NOTE:\n",
    "        # 1. in this case, no differentiation between global and subject-wise analysis\n",
    "        # 2. assuming a large sample size (n > 30) and checking for normality of the data\n",
    "        \n",
    "        # function to find the K value that is closer to K0:\n",
    "        def find_closest_Kvalue(arr, target):\n",
    "            closest_value = arr[0]  # Initialize with the first element\n",
    "            min_difference = abs(target - arr[0])  # Initialize with the difference to the first element\n",
    "            \n",
    "            # every time a closer element is found, the closest value is updated\n",
    "            for element in arr:\n",
    "                difference = abs(target - element)\n",
    "                if difference < min_difference:\n",
    "                    min_difference = difference\n",
    "                    closest_value = element\n",
    "            \n",
    "            return closest_value            \n",
    "        \n",
    "        # initialization:\n",
    "        df_humans_response_times_stats_appended = []\n",
    "        # - isolating data for each N value:\n",
    "        for i, N_value in enumerate(sorted(self.N_values)):\n",
    "            print(f\"Calculating response time stats for N = {N_value}\")\n",
    "            currentN_response_times = self.df_humans_response_times[self.df_humans_response_times['N'] == N_value]\n",
    "            # isolating data for the smallest K value:\n",
    "            smallest_K_value = currentN_response_times['K'].min()\n",
    "            # isolating data for the K value closest to K0:\n",
    "            closest_K_value = find_closest_Kvalue(currentN_response_times['K'].unique(), self.df_humans_fitted_params[self.df_humans_fitted_params['N'] == N_value]['K0'].mean())\n",
    "            # means and SEMs:\n",
    "            print(f\"Mean response times for smallest K value: {currentN_response_times[currentN_response_times['K'] == smallest_K_value]['mean_resp_time'].mean()} +- {sem(currentN_response_times[currentN_response_times['K'] == smallest_K_value]['mean_resp_time'])}\")\n",
    "            print(f\"Mean response times for closest K value: {currentN_response_times[currentN_response_times['K'] == closest_K_value]['mean_resp_time'].mean()} +- {sem(currentN_response_times[currentN_response_times['K'] == closest_K_value]['mean_resp_time'])}\")\n",
    "            # checking for normality:\n",
    "            print(\"Shapiro-Wilk test for normality:\")\n",
    "            print(f\"- for smallest K value: {shapiro(currentN_response_times[currentN_response_times['K'] == smallest_K_value]['mean_resp_time'])}\")\n",
    "            print(f\"- for closest K value: {shapiro(currentN_response_times[currentN_response_times['K'] == closest_K_value]['mean_resp_time'])}\")\n",
    "            # performing t-test:\n",
    "            t_test_stat = ttest_rel(currentN_response_times[currentN_response_times['K'] == closest_K_value]['mean_resp_time'], currentN_response_times[currentN_response_times['K'] == smallest_K_value]['mean_resp_time'], alternative='greater')\n",
    "            print(f\"t-test for N = {N_value}: {t_test_stat}\")\n",
    "            df_humans_response_times_stats_appended.append(pd.DataFrame({'N': [N_value], 't-statistic':[t_test_stat.statistic], 'p-value':[t_test_stat.pvalue]}))\n",
    "        # creating single df:\n",
    "        df_humans_response_times_stats = pd.concat(df_humans_response_times_stats_appended)\n",
    "        self.df_humans_response_times_stats = df_humans_response_times_stats\n",
    "        display(df_humans_response_times_stats)\n",
    "        \n",
    "        print(\"|Completed calculating response times stats.\")\n",
    "\n",
    "\n",
    "    def explore_visual_strategy(self):  \n",
    "        print(\"|Exploring visual strategy...\")\n",
    "        \n",
    "        #NOTE: the graph pool for the thesis data has been regenerated with additional variables, therefore the results of this analysis are not reliable. To run this analysis on thesis data, recover data from GitHub (HUPLACLIP-humans)\n",
    "        \n",
    "        # Description:\n",
    "        # Exploration of the strategy adopted by subjects to solve the task. The hypothesis is that the detection of the clique is facilitated when the clique is more \"clustered\" in the visualization that led to the final response.\n",
    "        # Possible improvements: \n",
    "        # - take into account the degree of clustering of the clique in the previous visualizations (not only in the final one)\n",
    "        # - take into account the time spent on each visualization before the final answer \n",
    "        \n",
    "        # defining a clustering measure:        \n",
    "        def clustering_score(clique_array, nodes_order):\n",
    "            # Get the positions of the clique nodes inside the current presentation\n",
    "            positions = [nodes_order.index(k) for k in clique_array]\n",
    "            positions.sort()\n",
    "\n",
    "            # Compute mean pairwise distance (MPD) between clique nodes\n",
    "            distances = [abs(i - j) for i, j in combinations(positions, 2)]\n",
    "            mpd = sum(distances) / len(distances) if distances else 0.0\n",
    "\n",
    "            # Compute closeness score\n",
    "            return 1 / (1 + mpd)       \n",
    "        \n",
    "        def retrieve_clique_array(graph_name, N_value, K_value):\n",
    "            # control: checking presence of N_value and K_value in the graph name:\n",
    "            if str(round(N_value)) not in graph_name or str(round(K_value)) not in graph_name:\n",
    "                raise ValueError(f\"Mismatch between graph name and N/K combination. Graph name {graph_name} does not contain N = {N_value} or K = {K_value}\")\n",
    "\n",
    "            # retrieving the original graph from the graph pool:\n",
    "            graph_pool_path = Path(f'../graph_pools')\n",
    "            if not graph_pool_path.exists():\n",
    "                raise ValueError(f\"Graph pool directory {graph_pool_path} does not exist\")\n",
    "\n",
    "            #TODO: dynamically retrieve p-correction type from experiment data (stored in \"browser-check\" trial)\n",
    "            graph_with_clique_path = graph_pool_path / \"p_reduce\" / f\"N{(round(N_value)):04}\" / \"CLIQUE\" / f\"{(round(K_value)):04}\" / f\"{graph_name}.json\"\n",
    "            if not graph_with_clique_path.exists():\n",
    "                raise ValueError(f\"Graph file {graph_with_clique_path} does not exist\")\n",
    "\n",
    "            try:\n",
    "                # Open and decompress the gzip file\n",
    "                with gzip.open(graph_with_clique_path, 'rb') as file:\n",
    "                    decompressed_data = file.read()\n",
    "                # Parse the decompressed JSON data\n",
    "                graph_with_clique = json.loads(decompressed_data.decode('utf-8'))     \n",
    "            except:\n",
    "                raise ValueError(f\"Error reading the file {graph_with_clique_path}\")\n",
    "            # retrieving the clique array from the graph (last line of the dictionary):\n",
    "            clique_array = list(graph_with_clique.items())[-1][1]['clique_array']\n",
    "            return clique_array\n",
    "        \n",
    "        # initializations:\n",
    "        df_humans_visual_strategy_appended = []\n",
    "        \n",
    "        # looping through all N values and clique sizes:\n",
    "        for N_value in sorted(self.N_values):\n",
    "            currentN_data = self.cleaned_data_final_resp[self.cleaned_data_final_resp.graph_size == N_value]\n",
    "            for K_value in currentN_data['clique_size'].unique():\n",
    "                currentK_data = currentN_data[currentN_data.clique_size == K_value]\n",
    "                # looping through all subjects for current N and K values:\n",
    "                for subject_number in currentK_data['subject_number'].unique():\n",
    "                    # isolating data of current N value, K value and subject number\n",
    "                    currentK_subject_data = currentK_data[currentK_data.subject_number == subject_number]\n",
    "                    # looping through each visualization for current N, K and subject values:\n",
    "                    for i, row in currentK_subject_data.iterrows():\n",
    "                        # accessing the name of the graph with the clique:\n",
    "                        graphs_names = json.loads(row.graphs_names)\n",
    "                        graph_with_clique_name = next((s for s in graphs_names if \"_CLIQUE\" in s), None)\n",
    "                        nodes_order = json.loads(row.nodes_order)\n",
    "                        # retrieving the clique array:\n",
    "                        clique_array = retrieve_clique_array(graph_with_clique_name, N_value, K_value)\n",
    "                        # calculating the clustering score for the current visualization:\n",
    "                        current_clustering_score = clustering_score(clique_array, nodes_order)\n",
    "                        # appending data to the list:\n",
    "                        df_humans_visual_strategy_appended.append(pd.DataFrame({'subject_number':[subject_number],'N':[N_value], 'K': [K_value], 'clustering_score':[current_clustering_score], 'correct': [row.correct if self.experiment_name != \"2023-06_thesis-data\" else row.accuracy]}))\n",
    "\n",
    "        # creating single df:\n",
    "        df_humans_visual_strategy = pd.concat(df_humans_visual_strategy_appended)\n",
    "        # saving dataframe:\n",
    "        self.df_humans_visual_strategy = df_humans_visual_strategy\n",
    "        # visualizing dataframe:\n",
    "        display(self.df_humans_visual_strategy)\n",
    "\n",
    "        print(\"|Completed exploring visual strategy.\")\n",
    "    \n",
    "    # def generate_visual_strategy_graphs(self):\n",
    "    #     print(\"|Generating visual strategy graphs...\")\n",
    "        \n",
    "    # def calculate_visual_strategy_stats(self):\n",
    "        # Description:\n",
    "        # - checking if the clustering score is significantly higher for correct responses than for incorrect responses\n",
    "\n",
    "        print(\"|Calculating visual strategy stats...\")\n",
    "        \n",
    "    \n",
    "    def generate_main_plot(self):\n",
    "        \n",
    "        print(\"|Generating main plot...\")\n",
    "        \n",
    "        # Create a smaller figure with specified size\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))  \n",
    "        \n",
    "        # - loop through the N values:\n",
    "        for i, N_value in enumerate(sorted(self.df_humans_fitted_params['N'].unique())):\n",
    "            # isolating data for current N value:\n",
    "            current_fitted_params = self.df_humans_fitted_params[self.df_humans_fitted_params['N'] == N_value]\n",
    "            if self.analysis_type == \"global\":\n",
    "                ax.scatter(N_value, current_fitted_params[current_fitted_params['N'] == N_value]['K0'].mean(), label=f'Humans ({N_value})', color=self.humans_palette_global[i], s=120, marker=\"^\")\n",
    "\n",
    "            elif self.analysis_type == \"subject-wise\":\n",
    "                # palette_subjects = sns.color_palette(\"husl\", len(current_fitted_params['subject_number'].unique()))\n",
    "                ax_humans = sns.scatterplot(data=current_fitted_params, x='N', y='K0', hue='subject_number', palette=self.humans_palette_subjects, legend=False, alpha=0.4, s=70, marker=\"^\")\n",
    "                ax_humans.scatter(N_value, current_fitted_params[current_fitted_params['N'] == N_value]['K0'].mean(), label=f'Humans ({N_value})', color=self.humans_palette_global[i], s=120, marker=\"^\")\n",
    "\n",
    "        # THEORETICAL AND COMPUTATIONAL LIMITS:\n",
    "        N = np.arange(0.1, 1200)\n",
    "        K_it = 2 * np.log2(N)\n",
    "        K_comp = np.sqrt(N / np.e)            \n",
    "        limits_palette = ['green', 'orange']\n",
    "        ax.plot(N, K_it, label='STAT limit', color=limits_palette[0])\n",
    "        ax.plot(N[:1125], K_comp[:1125], label='COMP limit', color=limits_palette[1], linestyle='dotted')\n",
    "        ax.plot(N[1125:], K_comp[1125:], color=limits_palette[1])\n",
    "\n",
    "        # Add axes labels to the plot\n",
    "        ax.set_xlabel('Number of nodes', size=12)\n",
    "        ax.set_ylabel('K₀ (clique detection threshold)', size=12)\n",
    "\n",
    "        # Log scale for y-axis:\n",
    "        if self.log_scale_K0:\n",
    "            ax.set_yscale('log', base=2)\n",
    "            ax.set_xlim(60, *ax.get_xlim()[1:])\n",
    "            ax.set_ylim(15, *ax.get_ylim()[1:])\n",
    "            # Using ScalarFormatter to format the y-axis with actual numbers instead of powers of 2\n",
    "            ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "        else:\n",
    "            ax.autoscale()      \n",
    "\n",
    "        # # Drawing linear fit of machines' K0s with points' color gradient\n",
    "        # TODO: perform linear fit on mean values of K0 for humans? In another function?\n",
    "        # y_values = slope * N + intercept\n",
    "        # ax.plot(N, y_values, color=my_palette_rudy[1], linestyle='--')\n",
    "              \n",
    "        # Customize legend:\n",
    "        # Customize legend:\n",
    "        # handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        # print(handles)\n",
    "        # print(labels)\n",
    "\n",
    "        # filtered_handles = []\n",
    "        # filtered_labels = []\n",
    "\n",
    "        # # List of labels you want to keep in the legend\n",
    "        # labels_to_keep = df_checkpoint_fitted_params['model'].values\n",
    "\n",
    "        # for handle, label in zip(handles, labels):\n",
    "        #     if label in labels_to_keep:\n",
    "        #         filtered_handles.append(handle)\n",
    "        #         filtered_labels.append(label)\n",
    "\n",
    "        # # Add a custom legend with only the desired elements\n",
    "        # ax.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5), title='Agents (Number of nodes):')        \n",
    "        ax.tick_params(axis='x')\n",
    "        ax.tick_params(axis='y')\n",
    "        \n",
    "        # Set title:\n",
    "        ax.set_title('Humans: K₀ as a function of N', size=14)\n",
    "                \n",
    "        # saving figure in corresponding \"plots/humans\" folder\n",
    "        if self.analysis_type == \"global\":\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-main-plot_{self.experiment_name}_global{\"_log-scaled\" if self.log_scale_K0 else \"\"}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-main-plot_{self.experiment_name}_global{\"_log-scaled\" if self.log_scale_K0 else \"\"}.png', dpi=300, bbox_inches=\"tight\")  \n",
    "        elif self.analysis_type == \"subject-wise\":\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-main-plot_{self.experiment_name}_subjects{\"_log-scaled\" if self.log_scale_K0 else \"\"}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/humans/{self.experiment_name}/humans-main-plot_{self.experiment_name}_subjects{\"_log-scaled\" if self.log_scale_K0 else \"\"}.png', dpi=300, bbox_inches=\"tight\")\n",
    "                         \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"|Completed generating main plot.\")    \n",
    "        \n",
    "        \n",
    "# Defining subclasses for each analysis type:\n",
    "    def fitted_params_humans(self):\n",
    "        self.read_raw_data()\n",
    "        self.clean_data()\n",
    "        self.calculate_fraction_correct()\n",
    "        self.calculate_fitted_params()\n",
    "        return self.df_humans_fitted_params, self.humans_palette_global    \n",
    "    \n",
    "    def shuffles_humans(self):\n",
    "        self.read_raw_data()\n",
    "        self.clean_data()\n",
    "        self.calculate_fraction_correct()\n",
    "        self.calculate_fitted_params()        \n",
    "        self.calculate_shuffles_df() \n",
    "        self.generate_shuffles_graphs()   \n",
    "        self.calculate_shuffles_stats()\n",
    "        \n",
    "    def response_times_humans(self):\n",
    "        self.read_raw_data()\n",
    "        self.clean_data()\n",
    "        self.calculate_fraction_correct()\n",
    "        self.calculate_fitted_params()\n",
    "        self.calculate_response_times_df()\n",
    "        self.generate_response_times_graphs()\n",
    "        self.calculate_response_times_stats()\n",
    "        \n",
    "    def strategy_humans(self):\n",
    "        self.read_raw_data()\n",
    "        self.clean_data()\n",
    "        self.explore_visual_strategy()\n",
    "        \n",
    "    def complete_human_pipeline(self):\n",
    "        self.read_raw_data()\n",
    "        self.calculate_demographics()\n",
    "        self.clean_data()\n",
    "        self.calculate_fraction_correct()\n",
    "        self.generate_boxplot()  \n",
    "        self.calculate_boxplot_stats()   \n",
    "        self.calculate_fitted_params()\n",
    "        self.generate_psychometrics()\n",
    "        self.calculate_shuffles_df()  \n",
    "        self.generate_shuffles_graphs()\n",
    "        self.calculate_shuffles_stats()\n",
    "        self.calculate_response_times_df()\n",
    "        self.generate_response_times_graphs()\n",
    "        self.calculate_response_times_stats()\n",
    "        # self.explore_visual_strategy()        \n",
    "        self.generate_main_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects for each N value:  15\n",
      "|Reading raw data...\n",
      "||Entered folder: data\\humans\\2023-06_thesis-data\\N1000\n",
      "||Entered folder: data\\humans\\2023-06_thesis-data\\N300\n",
      "|Completed reading raw data.\n",
      "|Cleaning data...\n",
      "Excluding 289 trials where response time is less than 100ms. 12318 trials remaining. Excluded 2.29% of trials.\n",
      "                     trial_type     rt    response  \\\n",
      "26867  canvas-keyboard-response  681.0               \n",
      "26871  canvas-keyboard-response  429.0               \n",
      "26873  canvas-keyboard-response  435.0               \n",
      "26875  canvas-keyboard-response  215.0               \n",
      "26877  canvas-keyboard-response  173.0  arrowright   \n",
      "\n",
      "                                             nodes_order correct_response  \\\n",
      "26867  [73,121,176,55,167,262,151,140,172,245,183,178...        arrowleft   \n",
      "26871  [26,122,7,191,116,196,259,277,283,58,109,24,25...        arrowleft   \n",
      "26873  [185,269,45,250,90,258,248,216,179,84,65,46,16...        arrowleft   \n",
      "26875  [84,198,245,30,42,241,150,190,212,134,129,67,2...        arrowleft   \n",
      "26877  [16,201,165,146,187,261,200,106,227,100,293,21...        arrowleft   \n",
      "\n",
      "       block_index  presentation_index  clique_size  graph_size  \\\n",
      "26867          5.0                28.0         10.0       300.0   \n",
      "26871          5.0                29.0         10.0       300.0   \n",
      "26873          5.0                29.0         10.0       300.0   \n",
      "26875          5.0                29.0         10.0       300.0   \n",
      "26877          5.0                29.0         10.0       300.0   \n",
      "\n",
      "                                            graphs_names accuracy  \\\n",
      "26867  [\"0078_N0300_K0010_CLIQUE\",\"0051_N0300_K0010_N...      NaN   \n",
      "26871  [\"0066_N0300_K0010_CLIQUE\",\"0009_N0300_K0010_N...      NaN   \n",
      "26873  [\"0066_N0300_K0010_CLIQUE\",\"0009_N0300_K0010_N...      NaN   \n",
      "26875  [\"0066_N0300_K0010_CLIQUE\",\"0009_N0300_K0010_N...      NaN   \n",
      "26877  [\"0066_N0300_K0010_CLIQUE\",\"0009_N0300_K0010_N...    False   \n",
      "\n",
      "       subject_number  \n",
      "26867              15  \n",
      "26871              15  \n",
      "26873              15  \n",
      "26875              15  \n",
      "26877              15  \n",
      "|Completed cleaning data.\n",
      "|Exploring visual strategy...\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 90.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 80.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 70.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 65.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 60.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 55.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 50.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 45.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 40.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 35.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 30.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 25.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 20.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 15.0, subject 15\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 1\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 2\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 3\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 4\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 5\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 6\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 7\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 8\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 9\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 10\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 11\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 12\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 13\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 14\n",
      "Exploring visual strategy for N = 300, K = 10.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 267.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 233.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 217.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 200.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 183.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 167.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 150.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 133.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 117.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 100.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 83.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 67.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 50.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 33.0, subject 15\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 1\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 2\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 3\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 4\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 5\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 6\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 7\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 8\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 9\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 10\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 11\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 12\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 13\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 14\n",
      "Exploring visual strategy for N = 1000, K = 300.0, subject 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_number</th>\n",
       "      <th>N</th>\n",
       "      <th>K</th>\n",
       "      <th>clustering_score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.009889</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5323 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_number     N      K  clustering_score  correct\n",
       "0                1   300   90.0          0.010257     True\n",
       "0                1   300   90.0          0.009656     True\n",
       "0                1   300   90.0          0.009889     True\n",
       "0                1   300   90.0          0.010382     True\n",
       "0                1   300   90.0          0.010345     True\n",
       "..             ...   ...    ...               ...      ...\n",
       "0               15  1000  300.0          0.002945     True\n",
       "0               15  1000  300.0          0.003060     True\n",
       "0               15  1000  300.0          0.002850     True\n",
       "0               15  1000  300.0          0.002870     True\n",
       "0               15  1000  300.0          0.003037     True\n",
       "\n",
       "[5323 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Completed exploring visual strategy.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the pipeline with the experiment name\n",
    "human_pipeline = HumanAnalysisPipeline(experiment_name=\"2023-06_thesis-data\", analysis_type=\"subject-wise\", log_scale_K0=True)\n",
    "\n",
    "# Run the entire pipeline\n",
    "# human_pipeline.complete_human_pipeline()\n",
    "\n",
    "human_pipeline.strategy_humans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for this code to work, the 'data/machines' folder needs to contain one sub-folder for each full experiment at one value of N. Each of these folders needs to have the N value as name (ex. '150', '400'...) and must contain the results for the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import colorcet as cc\n",
    "# from statsmodels.formula.api import ols\n",
    "from scipy.special import ndtr\n",
    "from scipy.optimize import curve_fit, differential_evolution\n",
    "# from scipy.stats import linregress, ttest_rel, spearmanr, shapiro, sem\n",
    "# from pathlib import Path\n",
    "from matplotlib import ticker\n",
    "from math import sqrt\n",
    "from math import log, e\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachinesAnalysisPipeline:\n",
    "\n",
    "    def __init__(self, experiment_name, variance_test=False, log_scale_K0=False):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.variance_test = variance_test\n",
    "        self.log_scale_K0 = log_scale_K0\n",
    "    \n",
    "        # Dynamically defining the palette based on the models present in the experiment:\n",
    "        # - defining the path to the experiment folder:\n",
    "        folder_path = os.path.join('data', 'machines', self.experiment_name)\n",
    "        # - loop over all folders in the experiment folder (each folder corresponds to an N value)\n",
    "        model_names_folders = []\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            if os.path.isdir(os.path.join(folder_path, folder_name)):\n",
    "                # - loop over all folders in the N folder and define list of model names:\n",
    "                for model_name in os.listdir(os.path.join(folder_path, folder_name)):\n",
    "                    if os.path.isdir(os.path.join(folder_path, folder_name, model_name)):\n",
    "                        model_names_folders.append(model_name)\n",
    "                        # check that the folder contains the metrics and the fraction correct file:\n",
    "                        file_path = os.path.join(folder_path, folder_name, model_name, f'{model_name}_N{folder_name}_metrics.csv')\n",
    "                        file_path = os.path.join(folder_path, folder_name, model_name, f'{model_name}_N{folder_name}_fraction_correct.csv')\n",
    "                        if not os.path.isfile(file_path):\n",
    "                            print(f\"Warning! File {file_path} does not exist, make sure to add the metrics and the fraction correct files in all folders.\")  \n",
    "        # Removing duplicate model names:\n",
    "        model_names_folders = list(set(model_names_folders))\n",
    "        \n",
    "        # Defining palette and model names based on the dataset:\n",
    "        if self.experiment_name == \"2025-02-26_li-earlystop-scatter\":\n",
    "            model_names_palette = ['MLP-old-pipeline', 'ViTscratch', 'ViTpretrained', 'Variance_test', 'CNN_large', 'MLP-new-pipeline', 'MLP_10layers', 'MLP_20layers', 'MLP_lr1e-5', 'MLP_old-pipeline-lr1e-5_10000steps']   # ADD MODEL NAMES HERE AND IN PALETTE BELOW  \n",
    "            # checking that all model names in the folders are present in the palette:\n",
    "            if not all(elem in model_names_palette for elem in model_names_folders):\n",
    "                print(f\"Warning! Model names in folders do not match the model names in the palette. Make sure to add all model names in the palette.\")\n",
    "            # defining custom palette:\n",
    "            machines_palette = {\n",
    "                'MLP-old-pipeline': sns.color_palette(cc.glasbey, len(model_names_palette))[0],\n",
    "                'ViTscratch': sns.color_palette(cc.glasbey, len(model_names_palette))[1],\n",
    "                'ViTpretrained': sns.color_palette(cc.glasbey, len(model_names_palette))[2],\n",
    "                'Variance_test': sns.color_palette(cc.glasbey, len(model_names_palette))[3],\n",
    "                'CNN_large': sns.color_palette(cc.glasbey, len(model_names_palette))[4],\n",
    "                'MLP-new-pipeline': sns.color_palette(cc.glasbey, len(model_names_palette))[5],\n",
    "                'MLP_10layers': sns.color_palette(cc.glasbey, len(model_names_palette))[6],\n",
    "                'MLP_20layers': sns.color_palette(cc.glasbey, len(model_names_palette))[7],\n",
    "                'MLP_lr1e-5': sns.color_palette(cc.glasbey, len(model_names_palette))[8],\n",
    "                'MLP_old-pipeline-lr1e-5_10000steps': sns.color_palette(cc.glasbey, len(model_names_palette))[9]\n",
    "            }  \n",
    "        elif self.experiment_name == \"2025-03-06_CNS-abstract\":\n",
    "            # in this case, not necessary to keep consistency with previous visualizations\n",
    "            model_names_palette = ['MLP', 'ViTscratch', 'ViTpretrained', 'Variance_test', 'CNN']\n",
    "            # checking that all model names in the folders are present in the palette:\n",
    "            if not all(elem in model_names_palette for elem in model_names_folders):\n",
    "                print(f\"Warning! Model names in folders do not match the model names in the palette. Make sure to add all model names in the palette.\")            \n",
    "            # defining custom palette:\n",
    "            machines_palette = {\n",
    "                'MLP': sns.color_palette(cc.glasbey, len(model_names_palette))[0],\n",
    "                'ViTscratch': sns.color_palette(cc.glasbey, len(model_names_palette))[1],\n",
    "                'ViTpretrained': sns.color_palette(cc.glasbey, len(model_names_palette))[2],\n",
    "                'Variance_test': sns.color_palette(cc.glasbey, len(model_names_palette))[3],\n",
    "                'CNN': sns.color_palette(cc.glasbey, len(model_names_palette))[4]\n",
    "            }          \n",
    "        else:\n",
    "            model_names_palette = ['MLP', 'ViTscratch', 'ViTpretrained', 'Variance_test', 'CNN', 'MLP_7layers', 'MLP_10layers', 'MLP_20layers', 'MLP_lr1e-5', 'MLP_lr1e-5_10000steps', 'MLP_li-earlystop-scatter']   # ADD MODEL NAMES HERE AND IN PALETTE BELOW  \n",
    "            # checking that all model names in the folders are present in the palette:\n",
    "            if not all(elem in model_names_palette for elem in model_names_folders):\n",
    "                print(f\"Warning! Model names in folders do not match the model names in the palette. Make sure to add all model names in the palette.\")               \n",
    "            # defining custom palette:\n",
    "            machines_palette = {\n",
    "                'MLP_old-pipeline': sns.color_palette(cc.glasbey, len(model_names_palette))[0],\n",
    "                'ViTscratch': sns.color_palette(cc.glasbey, len(model_names_palette))[1],\n",
    "                'ViTpretrained': sns.color_palette(cc.glasbey, len(model_names_palette))[2],\n",
    "                'Variance_test': sns.color_palette(cc.glasbey, len(model_names_palette))[3],\n",
    "                'CNN': sns.color_palette(cc.glasbey, len(model_names_palette))[4],\n",
    "                'MLP_7layers': sns.color_palette(cc.glasbey, len(model_names_palette))[5],\n",
    "                'MLP_10layers': sns.color_palette(cc.glasbey, len(model_names_palette))[6],\n",
    "                'MLP_20layers': sns.color_palette(cc.glasbey, len(model_names_palette))[7],\n",
    "                'MLP_lr1e-5': sns.color_palette(cc.glasbey, len(model_names_palette))[8],\n",
    "                'MLP_lr1e-5_10000steps': sns.color_palette(cc.glasbey, len(model_names_palette))[9],\n",
    "                'MLP_li-earlystop-scatter': sns.color_palette(cc.glasbey, len(model_names_palette))[10]\n",
    "            }\n",
    "        self.machines_palette = machines_palette\n",
    "    \n",
    "    \n",
    "    def retrieve_fraction_correct(self):\n",
    "        print(\"|Retrieving fraction correct...\")\n",
    "        \n",
    "        # defining the path to the experiment folder:\n",
    "        folder_path = os.path.join('data', 'machines', self.experiment_name)\n",
    "        df_machines_fraction_correct = pd.DataFrame()\n",
    "        \n",
    "        # loop over all folders in the experiment folder (each folder corresponds to an N value)\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            if os.path.isdir(os.path.join(folder_path, folder_name)):\n",
    "                # loop over all folders in the N folder (each folder corresponds to a model)\n",
    "                for model_name in os.listdir(os.path.join(folder_path, folder_name)):\n",
    "                    if os.path.isdir(os.path.join(folder_path, folder_name, model_name)):\n",
    "                        file_path = os.path.join(folder_path, folder_name, model_name, f'{model_name}_N{folder_name}_fraction_correct.csv')\n",
    "                        if os.path.isfile(file_path):\n",
    "                            df_fraction_correct = pd.read_csv(file_path)\n",
    "                            df_fraction_correct['model'] = model_name\n",
    "                            df_fraction_correct['N'] = folder_name\n",
    "                            df_machines_fraction_correct = pd.concat([df_machines_fraction_correct, df_fraction_correct], ignore_index=True)\n",
    "                        else:\n",
    "                            print(f\"File {file_path} does not exist.\")\n",
    "                    else:\n",
    "                        print(f\"Folder {model_name} is not a directory.\")\n",
    "            else:\n",
    "                print(f\"Folder {folder_name} is not a directory.\")\n",
    "        \n",
    "        # converting the 'N' column to integer type:\n",
    "        df_machines_fraction_correct['N'] = df_machines_fraction_correct['N'].astype(int)\n",
    "        self.df_machines_fraction_correct = df_machines_fraction_correct\n",
    "        \n",
    "        # visualizing dataframe:\n",
    "        display(df_machines_fraction_correct)  \n",
    "        print(\"|Completed retrieving fraction correct.\")\n",
    "         \n",
    "            \n",
    "    def calculate_fitted_params(self):\n",
    "        print(\"|Calculating fitted parameters...\")\n",
    "        \n",
    "        def sigmoid(k, k0, delta):\n",
    "            return (1+ndtr((k-k0)/delta))/2 \n",
    "        \n",
    "        # empty dataframe where fitted parameters will be stored:\n",
    "        df_machines_fitted_params_appended = []\n",
    "        \n",
    "        # looping through all N values:\n",
    "        for N_value in self.df_machines_fraction_correct['N'].unique():\n",
    "            # selecting trials for current N value:\n",
    "            current_data = self.df_machines_fraction_correct[self.df_machines_fraction_correct['N']==N_value]\n",
    "            # looping through all models for current N value:\n",
    "            for model in current_data['model'].unique():\n",
    "                # accessing data for current subject:\n",
    "                current_model_data = current_data[current_data['model'] == model]\n",
    "                # calculating fitted parameters:\n",
    "                fitted_params = curve_fit(sigmoid, current_model_data['clique size'], current_model_data['fraction correct'], p0=(70, 20))[0]\n",
    "                # adding fitted parameters to the dataframe (including log-scaled K0):\n",
    "                df_machines_fitted_params_appended.append(pd.DataFrame({'model':[model], 'N': [N_value], 'K0':[fitted_params[0]], 'Delta':[fitted_params[1]]}))                \n",
    "\n",
    "            if self.variance_test:\n",
    "                # adding K0 value of the Variance test to the dataframe:\n",
    "                folder_path = os.path.join('data', 'machines', self.experiment_name)\n",
    "                file_path = os.path.join(folder_path, f'{N_value}', 'Variance_test', f'Variance_test_N{N_value}_K0.csv')\n",
    "                print(file_path)\n",
    "                if os.path.isfile(file_path):\n",
    "                    df_K0_variance_test = pd.read_csv(file_path)\n",
    "                    df_machines_fitted_params_appended.append(pd.DataFrame({'model':['Variance_test'], 'N': [N_value], 'K0':[df_K0_variance_test['K0'][0]], 'Delta':\"Not Available\"}))\n",
    "                \n",
    "        # concatenating dataframe of fitted parameters:\n",
    "        df_machines_fitted_params = pd.concat(df_machines_fitted_params_appended)\n",
    "        # saving dataframe:\n",
    "        self.df_machines_fitted_params = df_machines_fitted_params\n",
    "        \n",
    "        # visualizing dataframe:\n",
    "        display(df_machines_fitted_params)\n",
    "        print(\"|Completed calculating fitted parameters.\")\n",
    "\n",
    "        \n",
    "    def metrics_summary(self):\n",
    "        print(\"|Generating metrics summary...\")\n",
    "            \n",
    "        # defining the path to the experiment folder:\n",
    "        folder_path = os.path.join('data', 'machines', self.experiment_name)\n",
    "        metrics_summary_df = pd.DataFrame()\n",
    "        \n",
    "        # loop over all folders in the experiment folder (each folder corresponds to an N value)\n",
    "        for folder_name in os.listdir(folder_path):\n",
    "            if os.path.isdir(os.path.join(folder_path, folder_name)):\n",
    "                # loop over all folders in the N folder (each folder corresponds to a model)\n",
    "                for model_name in os.listdir(os.path.join(folder_path, folder_name)):\n",
    "                    if os.path.isdir(os.path.join(folder_path, folder_name, model_name)):\n",
    "                        file_path = os.path.join(folder_path, folder_name, model_name, f'{model_name}_N{folder_name}_metrics.csv')\n",
    "                        if os.path.isfile(file_path):\n",
    "                            df_metrics_model = pd.read_csv(file_path)\n",
    "                            df_metrics_model['N'] = folder_name\n",
    "                            df_metrics_model['model'] = model_name\n",
    "                            # adding K0 value to the dataframe:\n",
    "                            df_metrics_model['K0'] = self.df_machines_fitted_params.loc[(self.df_machines_fitted_params['N'] == int(folder_name)) & (self.df_machines_fitted_params['model'] == model_name), 'K0'].values[0]\n",
    "                            metrics_summary_df = pd.concat([metrics_summary_df, df_metrics_model], ignore_index=True)\n",
    "                        else:\n",
    "                            print(f\"File {file_path} does not exist.\")\n",
    "                    else:\n",
    "                        print(f\"Folder {folder_name} is not a directory.\")\n",
    "                            \n",
    "        # write k0 column in decimal notation:\n",
    "        metrics_summary_df['K0'] = metrics_summary_df['K0'].apply(lambda x: '{:.2f}'.format(x))\n",
    "        # rounding all values to 2 decimal places:\n",
    "        metrics_summary_df = metrics_summary_df.round(2)\n",
    "        # place the 'model', 'N', 'K0' columns at the beginning of the dataframe:\n",
    "        cols = ['model', 'N', 'K0'] + [col for col in metrics_summary_df.columns if col not in ['model', 'N', 'K0']]\n",
    "        metrics_summary_df = metrics_summary_df[cols]\n",
    "\n",
    "        display(metrics_summary_df)\n",
    "        self.metrics_summary_df = metrics_summary_df\n",
    "        print(\"|Completed generating metrics summary.\")\n",
    "        \n",
    "        \n",
    "    # def compare_number_of_parameters(self):\n",
    "        #TODO: implement comparison of number of parameters across architectures, scaling by input size? (table)\n",
    "        \n",
    "        \n",
    "    def generate_psychometrics(self):\n",
    "        print(\"|Generating psychometric curves...\")\n",
    "\n",
    "        # Get the unique values as an iterable array of integers\n",
    "        unique_n_values = self.df_machines_fraction_correct['N'].unique()\n",
    "        unique_n_values = np.sort(unique_n_values)\n",
    "\n",
    "        # - create subplots based on the number of N values:\n",
    "        n_values = len(unique_n_values)\n",
    "        if n_values == 9:\n",
    "            rows = 3\n",
    "            cols = 3\n",
    "        else: \n",
    "            raise ValueError(f\"The number of N values should be 9, but is {n_values}. Check for errors in the code.\")\n",
    "        fig, ax = plt.subplots(rows, cols, figsize=(20, 15))\n",
    "\n",
    "        # Ensure ax is always a 2D array for consistency\n",
    "        ax = ax.flatten()\n",
    "\n",
    "        # - loop through the N values:\n",
    "        for i, N_value in enumerate(unique_n_values):\n",
    "            # isolating data for current N value:\n",
    "            current_data = self.df_machines_fraction_correct[self.df_machines_fraction_correct['N'] == N_value]\n",
    "            # filtering the data to include only the models for which k0 is smaller than N:\n",
    "            current_data = current_data[current_data['clique size'] < int(N_value)]\n",
    "            # getting the names of the models to filter the palette:\n",
    "            models_names = current_data['model'].unique()\n",
    "            # Filtering the palette\n",
    "            machines_palette_filtered = {key: self.machines_palette[key] for key in models_names}\n",
    "            # defining x values:\n",
    "            x_vals = np.linspace(0, 0.7 * int(N_value), 1000)\n",
    "\n",
    "            # drawing scatterplot based on fraction correct dataframe:\n",
    "            sns.scatterplot(data=current_data, x='clique size', y='fraction correct', ax=ax[i], s=10, hue='model', palette=machines_palette_filtered)\n",
    "            # defining y values and plotting the psychometric curve:\n",
    "            for model in models_names:\n",
    "                k0 = self.df_machines_fitted_params[(self.df_machines_fitted_params['N'] == N_value) & (self.df_machines_fitted_params['model'] == model)]['K0'].values[0]\n",
    "                delta = self.df_machines_fitted_params[(self.df_machines_fitted_params['N'] == N_value) & (self.df_machines_fitted_params['model'] == model)]['Delta'].values[0]\n",
    "                y_vals = (1 + ndtr((x_vals - k0) / delta)) / 2\n",
    "                ax[i].plot(x_vals, y_vals, color=machines_palette_filtered[model], label=model)\n",
    "\n",
    "            # setting labels and title for the subplot:\n",
    "            ax[i].set_ylabel(\"Fraction correct\")\n",
    "            ax[i].set_xlabel(\"Clique size\")\n",
    "            ax[i].set_title(f\"Psychometric curves for N = {int(N_value)}\")\n",
    "            ax[i].tick_params(axis='x')\n",
    "            ax[i].tick_params(axis='y')\n",
    "            ax[i].set_title(f\"Best models in {self.experiment_name} for N = {int(N_value)}\")\n",
    "\n",
    "        # Hide any unused subplots\n",
    "        for j in range(i + 1, len(ax)):\n",
    "            fig.delaxes(ax[j])\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # # Save plot as high resolution svg:\n",
    "        # if self.variance_test:\n",
    "        #     # - With variance test   \n",
    "        #     plt.savefig(f'./plots/machines/{self.experiment_name}/machines-psychometric-curves_{self.experiment_name}_Variance-test.svg', dpi=300, bbox_inches=\"tight\")\n",
    "        #     plt.savefig(f'./plots/machines/{self.experiment_name}/machines-psychometric-curves_{self.experiment_name}_Variance-test.png', dpi=300, bbox_inches=\"tight\")        \n",
    "        # else:\n",
    "        #     # - Without variance test\n",
    "        #     plt.savefig(f'./plots/machines/{self.experiment_name}/machines-psychometric-curves_{self.experiment_name}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "        #     plt.savefig(f'./plots/machines/{self.experiment_name}/machines-psychometric-curves_{self.experiment_name}.png', dpi=300, bbox_inches=\"tight\")  \n",
    "                        \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"|Completed generating psychometric curves.\")\n",
    "    \n",
    "\n",
    "    def generate_k0_plots(self):\n",
    "        print(\"|Generating K0 plot...\")\n",
    "        \n",
    "        # Get the unique values as an iterable array of integers\n",
    "        unique_n_values = self.df_machines_fraction_correct['N'].unique()\n",
    "        unique_n_values = np.sort(unique_n_values)\n",
    "\n",
    "        # - create subplots based on the number of N values:\n",
    "        n_values = len(unique_n_values)\n",
    "        if n_values == 9:\n",
    "            rows = 3\n",
    "            cols = 3\n",
    "        else: \n",
    "            raise ValueError(f\"The number of N values should be 9, but is {n_values}. Check for errors in the code.\")\n",
    "        fig, ax = plt.subplots(rows, cols, figsize=(16, 15))\n",
    "\n",
    "        # Ensure ax is always a 2D array for consistency\n",
    "        ax = ax.flatten()\n",
    "        \n",
    "        # - loop through the N values:\n",
    "        for i, N_value in enumerate(unique_n_values):\n",
    "            # isolating data for current N value:\n",
    "            current_fitted_params = self.df_machines_fitted_params[self.df_machines_fitted_params['N'] == N_value]\n",
    "            # filtering the data to keep only the models for which K0 is smaller than N:\n",
    "            current_fitted_params = current_fitted_params[current_fitted_params['K0'] < int(N_value)]\n",
    "            # Filtering the palette\n",
    "            machines_palette_filtered = {key: self.machines_palette[key] for key in current_fitted_params['model'].unique()}\n",
    "            # drawing swarmplot based on fraction correct dataframe:\n",
    "            \n",
    "            sns.swarmplot(data=current_fitted_params, x='N', y='K0', hue='model', palette=machines_palette_filtered, ax=ax[i], s=7)\n",
    "        \n",
    "            # Draw the statistical limit line\n",
    "            ax[i].axhline(y=2*np.log2(int(N_value)), color='g', linestyle=':')\n",
    "\n",
    "            # Adjust legend to include the statistical limit line\n",
    "            handles, labels = ax[i].get_legend_handles_labels()\n",
    "            # Append the statistical limit line handle and label\n",
    "            handles.append(plt.Line2D([], [], color='g', linestyle=':', label='STAT limit'))\n",
    "            labels.append('STAT limit')\n",
    "            ax[i].legend(handles=handles, labels=labels)\n",
    "        \n",
    "            # Add axes labels to the plot\n",
    "            ax[i].set_xlabel('Number of nodes', size=12)\n",
    "            ax[i].set_ylabel('K₀', size=12)\n",
    "            ax[i].set_title(f'Machines: K₀ as a function of N = {int(N_value)}', size=14)        \n",
    "        \n",
    "        # Hide any unused subplots\n",
    "        for j in range(i + 1, len(ax)):\n",
    "            fig.delaxes(ax[j])\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot as high resolution svg:\n",
    "        if self.variance_test:\n",
    "            # - With variance test   \n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-k0-plot_{self.experiment_name}_Variance-test.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-k0-plot_{self.experiment_name}_Variance-test.png', dpi=300, bbox_inches=\"tight\")        \n",
    "        else:\n",
    "            # - Without variance test\n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-k0-plot_{self.experiment_name}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-k0-plot_{self.experiment_name}.png', dpi=300, bbox_inches=\"tight\")  \n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"|Completed generating K0 plot.\")\n",
    "    \n",
    "\n",
    "    def generate_main_plot(self):\n",
    "        print(\"|Generating main plot...\")\n",
    "        \n",
    "        # Create a smaller figure with specified size\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))   \n",
    "        \n",
    "        # Loop through the N values:\n",
    "        for i, N_value in enumerate(self.df_machines_fitted_params['N'].unique()):\n",
    "            # Isolating data for the current N value:\n",
    "            current_fitted_params = self.df_machines_fitted_params[self.df_machines_fitted_params['N'] == N_value]\n",
    "             \n",
    "            # Filtering the data to keep only the models for which K0 is smaller than N:\n",
    "            current_fitted_params = current_fitted_params[current_fitted_params['K0'] < int(N_value)]\n",
    "            # Filtering the palette\n",
    "            machines_palette_filtered = {key: self.machines_palette[key] for key in current_fitted_params['model'].unique()}\n",
    "            \n",
    "            # Add a small jitter to the N column to avoid overlap\n",
    "            jittered_x = current_fitted_params['N'] + np.random.uniform(-10, 10, size=len(current_fitted_params))\n",
    "\n",
    "            # Draw scatterplot with jittered x values (only drawing one legend)\n",
    "            sns.scatterplot(data=current_fitted_params, x=jittered_x, y='K0', hue='model', \n",
    "                            palette=machines_palette_filtered, legend=(N_value == 400 or N_value == 800), s=50, ax=ax)    # Only draw legend for N=400 (contains MLP variants)\n",
    "\n",
    "        # THEORETICAL AND COMPUTATIONAL LIMITS:\n",
    "        N = np.arange(0.1, 1200)\n",
    "        K_it = 2 * np.log2(N)\n",
    "        K_comp = np.sqrt(N / np.e)            \n",
    "        limits_palette = ['green', 'orange']\n",
    "        ax.plot(N, K_it, label='STAT limit', color=limits_palette[0])\n",
    "        ax.plot(N[:1125], K_comp[:1125], label='COMP limit', color=limits_palette[1], linestyle='dotted')\n",
    "        ax.plot(N[1125:], K_comp[1125:], color=limits_palette[1])\n",
    "        \n",
    "        # Add axes labels to the plot\n",
    "        ax.set_xlabel('Number of nodes', size=12)\n",
    "        ax.set_ylabel('K₀ (clique detection threshold)', size=12)\n",
    "\n",
    "        if self.log_scale_K0:\n",
    "            ax.set_yscale('log', base=2)\n",
    "            ax.set_xlim(60, *ax.get_xlim()[1:])\n",
    "            ax.set_ylim(15, *ax.get_ylim()[1:])\n",
    "            # Using ScalarFormatter to format the y-axis with actual numbers instead of powers of 2\n",
    "            ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "        else:\n",
    "            ax.autoscale()        \n",
    "\n",
    "        # Customize legend:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        filtered_handles = []\n",
    "        filtered_labels = []\n",
    "        seen_labels = set()\n",
    "\n",
    "        # Filter out duplicate elements in the legend\n",
    "        for handle, label in zip(handles, labels):\n",
    "            if label not in seen_labels:\n",
    "                filtered_handles.append(handle)\n",
    "                filtered_labels.append(label)\n",
    "                seen_labels.add(label)\n",
    "\n",
    "        print(filtered_labels)        \n",
    "\n",
    "        # Add a custom legend with only the desired elements\n",
    "        ax.legend(filtered_handles, filtered_labels, loc='center left', bbox_to_anchor=(1, 0.5), title='Legend:')\n",
    "\n",
    "        # Set title:\n",
    "        ax.set_title('Machines: K₀ as a function of N', size=14)\n",
    "        \n",
    "        plt.grid()\n",
    "                \n",
    "        # Save plot as high resolution svg:\n",
    "        if self.variance_test:\n",
    "            # - With variance test   \n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-main-plot_{self.experiment_name}_Variance-test{\"_log-scaled\" if self.log_scale_K0 else \"\"}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-main-plot_{self.experiment_name}_Variance-test{\"_log-scaled\" if self.log_scale_K0 else \"\"}.png', dpi=300, bbox_inches=\"tight\")        \n",
    "        else:\n",
    "            # - Without variance test\n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-main-plot_{self.experiment_name}{\"_log-scaled\" if self.log_scale_K0 else \"\"}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "            plt.savefig(f'./plots/machines/{self.experiment_name}/machines-main-plot_{self.experiment_name}{\"_log-scaled\" if self.log_scale_K0 else \"\"}.png', dpi=300, bbox_inches=\"tight\")  \n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"|Completed generating main plot.\")\n",
    "\n",
    "  \n",
    "    def fitted_params_machines(self):\n",
    "        self.retrieve_fraction_correct()\n",
    "        self.calculate_fitted_params()\n",
    "        return self.df_machines_fitted_params, self.machines_palette    \n",
    "  \n",
    "    def complete_machines_pipeline(self):\n",
    "        self.retrieve_fraction_correct()\n",
    "        self.calculate_fitted_params()\n",
    "        self.metrics_summary()\n",
    "        self.generate_psychometrics()\n",
    "        self.generate_k0_plots()\n",
    "        self.generate_main_plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Instantiate the pipeline with the experiment name\n",
    "exp_name = \"2025-02-26_li-earlystop-scatter\" # ADD EXPERIMENT NAME HERE\n",
    "machines_pipeline = MachinesAnalysisPipeline(experiment_name=exp_name, variance_test=False, log_scale_K0=True)\n",
    "\n",
    "# Run the entire pipeline\n",
    "machines_pipeline.complete_machines_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rudy's data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has been given to us by Rudy, and is reported in the format he gave us at:\n",
    "\n",
    "`C:\\Users\\danie\\OneDrive - Università Campus Bio-Medico di Roma\\Project-backup\\HUPLACLIP - analysis\\pilot_2_horizontal\\Pilot2-combined-analysis.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "rudy_data = {\n",
    "    \"N\": [300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    \"K0\": [58.807378, 68.460279, 69.274007, 83.711061, 77.293921, 99.021618, 97.063763, 120.421003],\n",
    "    \"Delta\": [33.296757, 32.858235, 25.201322, 32.531213, 27.540676, 43.135570, 32.509116, 58.510465],\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_rudy_fitted_params = pd.DataFrame(rudy_data)\n",
    "\n",
    "# Display the Dataframe:\n",
    "df_rudy_fitted_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "# fitting linearly K0 as a function of N and storing slope and intercept:\n",
    "slope, intercept, r_value, p_value, std_err = linregress(df_rudy_fitted_params['N'], df_rudy_fitted_params['K0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Selecting data and calling the pipelines to calculate the fitted parameters from the raw data:\n",
    "# - humans\n",
    "exp_name_humans = \"2023-06_thesis-data\" # CHANGE THIS TO THE CORRECT EXPERIMENT NAME\n",
    "analysis_type = \"global\"\n",
    "# - machines\n",
    "exp_name_machines = \"2025-03-06_CNS-abstract\"   # CHANGE THIS TO THE CORRECT EXPERIMENT NAME\n",
    "variance_test = False\n",
    "# common parameter:\n",
    "log_scale_K0 = True\n",
    "\n",
    "# - humans\n",
    "human_pipeline = HumanAnalysisPipeline(experiment_name=exp_name_humans, analysis_type=analysis_type, log_scale_K0=log_scale_K0)\n",
    "df_humans_fitted_params, humans_palette = human_pipeline.fitted_params_humans()\n",
    "print(\"Completed fitted parameters calculation for humans.\")\n",
    "\n",
    "# - machines\n",
    "machines_pipeline = MachinesAnalysisPipeline(experiment_name=exp_name_machines, variance_test=variance_test, log_scale_K0=log_scale_K0)\n",
    "df_machines_fitted_params, machines_palette = machines_pipeline.fitted_params_machines()\n",
    "print(\"Completed fitted parameters calculation for machines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing square-root/linear relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: test compatibility of human/machine/combined data with square-root/linear relationship, and visualize in \"phases\" plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main, combined plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smaller figure with specified size\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# HUMAN DATA:\n",
    "# TODO: GENERALIZE TO HANDLE MORE THAN TWO N VALUES\n",
    "humans_mean_palette = sns.color_palette(\"flare\", 1) # TO REMOVE, RETRIEVE FROM HUMAN PIPELINE, FOR CONSISTENCY\n",
    "if analysis_type == \"global\":\n",
    "    ax.scatter(300, df_humans_fitted_params[df_humans_fitted_params['N'] == 300]['K0'].mean(), label='Humans (mean)', color=humans_mean_palette[0], s=120, marker=\"^\", alpha=0.5)\n",
    "    ax.scatter(1000, df_humans_fitted_params[df_humans_fitted_params['N'] == 1000]['K0'].mean(), color=humans_mean_palette[0], s=120, marker=\"^\", alpha=0.5)\n",
    "elif analysis_type == \"subject-wise\":    \n",
    "    humans_palette_subjects = sns.color_palette(\"flare\", len(df_humans_fitted_params['subject_number'].unique()))\n",
    "    ax_humans = sns.scatterplot(data=df_humans_fitted_params, x='N', y='K0', hue='subject_number', palette=humans_palette_subjects, legend=False, alpha=0.4, s=70, marker=\"^\")\n",
    "    ax_humans.scatter(300, df_humans_fitted_params[df_humans_fitted_params['N'] == 300]['K0'].mean(), label='Humans (mean)', color=humans_mean_palette[0], s=120, marker=\"^\")\n",
    "    ax_humans.scatter(1000, df_humans_fitted_params[df_humans_fitted_params['N'] == 1000]['K0'].mean(), color=humans_mean_palette[0], s=120, marker=\"^\")\n",
    "\n",
    "# MACHINES DATA:\n",
    "# Loop through the N values:\n",
    "for i, N_value in enumerate(df_machines_fitted_params['N'].unique()):\n",
    "    # Isolating data for the current N value:\n",
    "    current_fitted_params = df_machines_fitted_params[df_machines_fitted_params['N'] == N_value]\n",
    "    # Filtering the data to keep only the models for which K0 is smaller than N:\n",
    "    current_fitted_params = current_fitted_params[current_fitted_params['K0'] < int(N_value)]\n",
    "    # Filtering the palette\n",
    "    machines_palette_filtered = {key: machines_palette[key] for key in current_fitted_params['model'].unique()}\n",
    "    \n",
    "    # Add a small jitter to the N column to avoid overlap\n",
    "    jittered_x = current_fitted_params['N'] + np.random.uniform(-8, 8, size=len(current_fitted_params))\n",
    "    \n",
    "    # Draw scatterplot with jittered x values (only drawing one legend)\n",
    "    sns.scatterplot(data=current_fitted_params, x=jittered_x, y='K0', hue='model', \n",
    "                    palette=machines_palette_filtered, legend=(N_value == 400 or N_value == 800), s=50, ax=ax, alpha=0.7) # Only draw legend for N=400 or N=800, to retrieve names of all models\n",
    "\n",
    "# RUDY'S DATA:\n",
    "#sns.scatterplot(data=df_rudy_fitted_params, x='N', y='K0', label='CNN-rudy', color='orange', s=70, marker='s', alpha=0.5, ax=ax)\n",
    "# Drawing linear fit of Rudy's datapoints color gradient\n",
    "# y_values = slope * N + intercept\n",
    "# ax.plot(N, y_values, color=my_palette_rudy[1], linestyle='--')    \n",
    "\n",
    "#TODO: ADD VARIANCE TEST AS SEPARATE LINE IN THE PLOT    \n",
    "    \n",
    "# THEORETICAL AND COMPUTATIONAL LIMITS:\n",
    "N = np.arange(0.1, 1200)\n",
    "K_it = 2 * np.log2(N)\n",
    "K_comp = np.sqrt(N / np.e)            \n",
    "limits_palette = ['green', 'orange']\n",
    "ax.plot(N, K_it, label='STAT limit', color=limits_palette[0])\n",
    "ax.plot(N[:1125], K_comp[:1125], label='COMP limit', color=limits_palette[1], linestyle='dotted')\n",
    "ax.plot(N[1125:], K_comp[1125:], color=limits_palette[1])\n",
    "\n",
    "# Add axes labels to the plot\n",
    "ax.set_xlabel('Number of nodes', size=12)\n",
    "ax.set_ylabel('K₀ (clique detection threshold)', size=12)\n",
    "\n",
    "# Automatically adjust the x-axis and y-axis limits to fit the data  \n",
    "if log_scale_K0:\n",
    "    ax.set_yscale('log', base=2)\n",
    "    ax.set_xlim(60, *ax.get_xlim()[1:])\n",
    "    ax.set_ylim(15, *ax.get_ylim()[1:])\n",
    "    # Using ScalarFormatter to format the y-axis with actual numbers instead of powers of 2\n",
    "    ax.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "else:\n",
    "    ax.autoscale()\n",
    "\n",
    "# Customize legend:\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "filtered_handles = []\n",
    "filtered_labels = []\n",
    "seen_labels = set()\n",
    "\n",
    "# Filter out duplicate elements in the legend\n",
    "for handle, label in zip(handles, labels):\n",
    "    if label not in seen_labels:\n",
    "        filtered_handles.append(handle)\n",
    "        filtered_labels.append(label)\n",
    "        seen_labels.add(label)\n",
    "\n",
    "# Add a custom legend with only the desired elements\n",
    "ax.legend(filtered_handles, filtered_labels, loc='center left', bbox_to_anchor=(1, 0.5), title='Legend:')\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "# Save plot as high resolution svg:\n",
    "if variance_test:\n",
    "    plt.savefig(f'./plots/comparison/comparison-graph_{exp_name_humans}-{exp_name_machines}_Variance-test{\"_subject-wise\" if analysis_type == \"subject-wise\" else \"_global\"}{\"_log-scaled\" if log_scale_K0 else \"\"}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(f'./plots/comparison/comparison-graph_{exp_name_humans}-{exp_name_machines}_Variance-test{\"_subject-wise\" if analysis_type == \"subject-wise\" else \"_global\"}{\"_log-scaled\" if log_scale_K0 else \"\"}.png', dpi=300, bbox_inches=\"tight\")\n",
    "else:\n",
    "    plt.savefig(f'./plots/comparison/comparison-graph_{exp_name_humans}-{exp_name_machines}{\"_subject-wise\" if analysis_type == \"subject-wise\" else \"_global\"}{\"_log-scaled\" if log_scale_K0 else \"\"}.svg', dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(f'./plots/comparison/comparison-graph_{exp_name_humans}-{exp_name_machines}{\"_subject-wise\" if analysis_type == \"subject-wise\" else \"_global\"}{\"_log-scaled\" if log_scale_K0 else \"\"}.png', dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
