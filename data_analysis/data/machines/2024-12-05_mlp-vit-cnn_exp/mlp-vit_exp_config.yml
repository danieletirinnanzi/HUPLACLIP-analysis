exp_name: mlp-vit_exp
graph_size_values: 
# NOTE: to perform single experiments, simply comment the graph size values that are not needed
  - 100
  - 150
  - 200
  - 300
  - 400
  - 480
  - 600
  - 800
  - 1200
  
# type of correction to use (in graphs_generation.py):
# - p_increase (old correction): increasing the p value of the graph without the clique so that the average degree is matched between the two graphs
# - p_reduce (new correction): reducing the p value of the graph where the clique will be added
p_correction_type: p_reduce

training_parameters:
  # training steps:
  num_training_steps: 1000
  # training and validation set sizes:
  num_train: 32
  num_val: 32
  # other hyperparameters:
  learning_rate: 0.0001  # TO ADJUST
  # ADDITIONAL PARAMETERS GO HERE AND WILL BE READ IN train_test.py (line 106)
  # training structure:
  max_clique_size_proportion: 0.5 # during training, clique will be at most 50% of the graph size
  # min_clique_size_proportion: 0.3 NOT USED, min clique size is statistical limit
  clique_training_levels: 10
  save_step: 10
  # optimizer and loss function:
  optimizer: AdamW
  loss_function: BCELoss
  # early stopping:
  patience: 50  # since this makes the model move to the following training instance, it is more stringent
  min_delta: 0.01
  val_exit_loss: 0.1

testing_parameters:
  max_clique_size_proportion_test: 0.7 # during testing, clique will be at most 70% of the graph size
  num_test: 32  # number of graphs in each test iteration
  clique_testing_levels: 100  # number of different clique sizes to test (will be the number of datapoints in the test set)
  test_iterations: 16


models:
# NOTE: to perform single experiments, simply comment the models that are not needed.
# Each instance of "models" will be trained and tested
  
  - model_name: MLP
    architecture:
      l1: 200
      l2: 100
      l3: 25
      l4: 12
      dropout_prob: 0.2
    
  - model_name: ViTscratch

  - model_name: ViTpretrained