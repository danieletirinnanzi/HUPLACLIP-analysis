exp_name: cnn_exp
graph_size_values: 
# NOTE: to perform single experiments, simply comment the graph size values that are not needed
  - 100
  - 150
  - 200
  - 300
  - 400
  - 480
  - 600
  - 800
  - 1200
  
# type of correction to use (in graphs_generation.py):
# - p_increase (old correction): increasing the p value of the graph without the clique so that the average degree is matched between the two graphs
# - p_reduce (new correction): reducing the p value of the graph where the clique will be added
p_correction_type: p_reduce

training_parameters:
  # training steps:
  num_training_steps: 1000
  # training and validation set sizes:
  num_train: 32
  num_val: 32
  # other hyperparameters:
  learning_rate: 0.0001  # TO ADJUST
  # ADDITIONAL PARAMETERS GO HERE AND WILL BE READ IN train_test.py (line 106)
  # training structure:
  max_clique_size_proportion: 0.5 # during training, clique will be at most 50% of the graph size
  # min_clique_size_proportion: 0.3 NOT USED, min clique size is statistical limit
  clique_training_levels: 10
  save_step: 10
  # optimizer and loss function:
  optimizer: AdamW
  loss_function: BCELoss
  # early stopping:
  patience: 50  # since this makes the model move to the following training instance, it is more stringent
  min_delta: 0.01
  val_exit_loss: 0.1

testing_parameters:
  max_clique_size_proportion_test: 0.7 # during testing, clique will be at most 70% of the graph size
  num_test: 32  # number of graphs in each test iteration
  clique_testing_levels: 100  # number of different clique sizes to test (will be the number of datapoints in the test set)
  test_iterations: 16

models:
# NOTE: to perform single experiments, simply comment the models that are not needed.
# Each instance of "models" will be trained and tested

  - model_name: CNN_large
    architecture:
      num_conv_layers: 6
      c0: 1
      c1: 32
      c2: 64
      c3: 128
      c4: 256
      c5: 512
      c6: 512
      l1: 1024
      kernel_size_conv: [30, 30, 30, 30, 30, 30]
      stride_conv: [1, 1, 1, 1, 1, 1]
      padding_conv: [1, 1, 1, 1, 1, 1]
      kernel_size_pool: 2
      stride_pool: 2
      dropout_prob: 0.3 
      # OUT: (512, 10, 10)

